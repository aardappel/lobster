- namespace improvements:
  - Declaring a variable (or function) that has the same name as a namespace should be an error? (poll so far: yes)
  - obj.foo where foo is a method in a namespace should work if obj already has that namespaced type?
  - any more builtins to namespace?
  - move namespace parsing to parser!
  - Should obj.ns.fun() be disallowed (poll so far: no)
  - Should you be able to "import" namespaces? Most languages have this, but it is kind of an anti-feature since
    it make things harder to recognize without its namespace in front.
    Really, don't put things in a namespace if you don't effectively want to make it part of the name.

- Debug dump improvements:
  - automatically zip these files, can be 5x smaller.
  - Turn C++ crashes into Lobster errors so they can be saved with a lot of context.
  - For cycle objects, instead save object ids so a viewer can still find the original objects?

- auto binding generated C++ headers from a Lobster decl

- allow let inside if/guard as syntactic sugar

- this is out of date and a bit overly negative: https://aardappel.github.io/lobster/philosophy.html

- A document that explains what samples are available and what they demo.
  - Also move some more of my (Wouter) projects into the main repo as samples.

- People often call function values out of context and then get surprising errors.
  Make sure error at call site pinpoints which free var is not in scope to make
  this not work.

- Unknown functions in untypechecked code do not error at all anymore?

- Check if these are fixed by now:
    https://github.com/wolfpld/tracy/issues/419
    https://github.com/wolfpld/tracy/issues/422

- move this TODO.txt to github issues?
  - That's going to create 100+ issues, and not necessarily easier to overview since github doesn't have a good way to
    order issues by priority, and search for things.
    - Actually, the new "projects" can order issues both by a rough priority status, and also within that item by item.
    - Creating an issue for each bullet point here would be chaos indeed, but
      first sorting this entire file by language feature or system area, and then creating issues
      with sub-parts of those indicated by "- [ ]" which creates checkboxes than can show progress.
      - Pasting the bullets from here mostly creates correctly formatted bullets in github so
        can be done without too much extra formatting work.
    - Easier to refer people who want to know what is planned and/or want to help.
  - Right now, searches for keywords hit both code and this TODO.txt.

- We should be making extensive use of https://devblogs.microsoft.com/cppblog/introducing-vector-calling-convention/
  Especially since we're a closed static build we control, meaning we have no worries of
  ABI/calling convention mismatches.
  This would give a bunch of "free" performance boosts in places and likely allow the
  optimizer to do a better job.

- .xy is very frequently used.. why don't we have xyz -> xy conversion in the language,
  implemented as a struct shortening op?
  warning, if the struct is KEEP and contains refs in the chopped fields, it would need
  drops.

- maybe add some standard #defines for Lobster GLSL for int3/float3,
  we'd be a lot closer to universally readable math code (minus
  the C/Python syntax differences, so still not fully copy-pastable).

- Get Lobster VSCode plugin/LSP to work well - @ewoudje
  - Implement a --breakpoints that allows inserting of breakpoints as indicated by the plugin?
    Would not allow changing these during runtime but this is already way better than breakpoint()
    manually.
  - LSP: list members etc.
  - VSCode double click on errors doesn't work, why is that?

- consider using something else instead of _ for namespaces
    .	JS/TS, Ada, C#, CoffeeScript, E, F#, Go, Haskell, Java, Modula-3, OCaml, Pascal, Python, Ruby, SML, Squeak
    :	XML
    ::	Rust, C++, merd, Perl, Ruby, Squeak, Tcl, YCP
    : ::(69)	Common Lisp
    :-	Maple
    '	Perl
    `	Mathematica
    __	Mercury
    /	Matlab

- rename vectors to lists.. "vector" is confusing for non-C++ people apparently.

- "error: dynamic function value call must be on variable" can we remove this restriction?

- By-value assignment operator, for things like re-initializing objects:
  this <== Foo {}
  A bit inefficient in terms of construction/reference counting compared to a dedicated
  "placement new" syntax, but this can be used from other objects, instead of copy(),
  and could even be useful with vector/string etc.
  Note: since this does the equivalent of assigning every field, need to take care this
  gets registered with lifetime tracking / flow-sensitive typing.

- consider adding an interface/trait feature to make our compile time duck typing
  more controllable.
  - It would specify a list of function signatures for a type T.
  - It can be attached to different things to enforce a check if those functions are
    available for T, and produce an early/clear error if not.
    - as part of a struct/class decl.
    - as part of a generic argument to contrain the generic parameter.
  - It would be purely an error checking feature as it wouldn't actually do anything!

- & is not implemented for structs.

- Enable writing to struct fields.
  Maybe explicit opt in per field or per struct? If per field then also can do the opposite for
  read-only class members.

- Migrate to SDL 3:
  https://www.libsdl.org/gdc2023/
  https://github.com/libsdl-org/SDL/blob/main/docs/README-migration.md

- recursive class causes typechecker assert even before it runs out of stack:
    class C:
        s = "s"
        c = C {}
    print C {}

- this fails to specialize for the nil case:

    let a:[int]? = nil

    def f():
        return a[0]

    print if a:
        f()
    else:
        f()

- For a Foo { .. }, the parser does resolution of initialized/named fields, but for T { .. } whatever args
  are given are applied in-order, which is probably not expected. Either:
  a) This resolution needs to be moved from parser to type checker (requiring us to add tags: unprocessed to the AST)
  b) We recognise T { .. } (or make it a special node type) in the type checker and duplicate the parser logic
     there. Even so, it be nice to allow tags:, which would just require the same as a).

- a switch where all cases assign a non-nil value to nil variable doesn't make the var non-nil like if-then does.

- very easy optimisation: the bulk of binary ops have the second arg as constant.
  Making specialized ops for these not only generated way more efficient code,
  but the div by 0 case can be filtered out at compile time too etc.
  That said, this kind of micro optimisation probably better done once the C/C++ generation is
  inlined in the codegen.

- debugger todo
  - "d" in sample without value?
  - doesn't show some global constants inited?
  - Mark all stack-frames up to breakpoint (and maybe assert) as no-inline, then increase limits for all other functions?
  - Add custom view for textures, or any resource types..
  - Add a small source code view, will help quickly spotting the problem.
    - Maybe a "Source" treenode at the end of each stack frame item?
  - Better docs for all this?
  - Add user-specified UI for structs/classes?
  - just omit uninit vars? but only in debug...
  - A debugging mode where a breakpoint can be set when the programming is already running?
    Would be expensive to have a breakpoint check between every statement..
    But this would enable traditional step by step debugging.

- Inline structs, further improvements:
  - These were immutable in the past, because values were shared by pointer, but now there
    really is no reason to anymore, as they're always copied, so modifying a field of
    a struct that sits in a variable would totally be fine and useful.
    - allow fields in a struct to be preceded by var, and similarly in a class by let
      to change their respective defaults.
    - Will greatly expand the zero abstraction use cases where
    - once structs are mutable, maybe introduce a way to annotate both structs and classes
      as immutable?
  - can maybe simplify some of type checker now that certain ops don't ever deal with refs,
    for anything vector related, like MathCheckVector
  - finally split builtins into one op per len.
    - get rid of ToVStruct etc.
    - get rid of most of GenValueSize
  - look which ops are most frequent, then specialize them to 1/2/3/4/v widths, as even
    ts_memcpy still has a cost.
  - push() for non-struct has superfluous pushint 1.
  - Support mixed refc/scalar fields in structs.
    - then use this for FlatBuffers handles.
  - Extend functionality of having different sized values to also allow 8/16/32/64 bits items,
    especially in vectors, then structs..
    You'd have to somehow indicate that multiple fields are stored in the same 64-bit slot,
    because too much of the VM assumes everything is 64-bit Values.
    Thus, getting such smaller fields to work generically with all vector ops likely wouldn't
    work.. yet the type system would suggest it would, so a bit messy.
    Truely supporting smaller sizes in more places (e.g. a vector of int16) would be easier
    if all vector ops were code-genned instead of calling into generic methods, i.e.
    after bytecode has been factored out.
    An alternative would be a new kind of type, "bitfield", that is simply a subtype of int
    much like enums. You specify it like a struct, then that type can be used absolutely
    everywhere, and decay to an int for code that doesn't understand it.
    You still would have convenient accessors to read and write these values.
    An even cheaper way to add them would be to piggyback on the existing enum_flags,
    and have a way to specify bit-sizes instead of bit-offsets. Then using .enumval
    on any enum typed integer anywhere would retrieve the corresponding bits, or set them.
    That would work without structs needing to learn about overlapping fields.
    However, having them as consecutive overlapping fields in structs/classes would be
    the most powerful, as that would allow existing fields to be squeezed together and
    still work the same for all existing code, including serialization etc.
    Yet another alternative is to make buffers with views on them more of a first class
    language feature to replace write_int8_le and friends.
  - somehow not store LVector::width.

- Now that we have inline structs, ADTs (tagged unions) should be based on them, since
  being same-sized and being inline go so wonderfully together!
  - This would make types like Maybe/Optional etc super cheap.
  - don't even need to invent some separate enum/adt feature and use pattern matching for this,
    structs that participate in an inheritance hierarchy can simply have a typeinfo prefixed,
    ONLY when they are in a context of the superclass! That is even more efficient than enums
    in Rust, which presumably always carry their tag. In fact it is more similar to "fat" trait
    pointers in Rust, except without the pointers. A tagged struct can even shrink to not need
    the padding to bring all these structs to the same size.. and all this is easy because they're
    always copied.
- Rust's same-size ADTs with value semantics allow interesting copy-over use cases that are not
  possible in even C++, where there is no need to update pointers to an object.
  Maybe we can have a declaration in Lobster that forces a certain set of derived classes to be
  padded to the same size, with a special overwrite operator. The type of the variable would need
  to be of the superclass, and the superclass itself should maybe not be instantiable, or also be
  the same size.
  Basically you'd declare the superclass as everything below here is same size.
  What are examples of algorithms that could be simpler this way?
  - game objects changing state
  - AST node being changed
  - Type variables! This one is hard to do without.
  - Values in an interpreter
  Though most of these are easy to do with existing code.. it is more to avoid allocation and
  allow these values to be inline? Without inline values, you first have to construct on the heap
  before overwrite. Still useful to be possible for cases like type variables.
- Features to make it easier to use structs ADT style as opposed to inheritance
  - ADT is similar to a base class with no members and a fixed set of sub-classes.
    - So make that use case into a simpler declaration syntax.
  - extend switch to do ADTs.
- Might be better to not piggy-back on struct inheritance.
  - It really does a different thing, where with normal inheritance the base class is not expected
    to be the max size of all subclasses.
  - If you convert an xyz to an xy, you expect to get an xy instance with 2 fields, not 4 fields
    (type + max of subclasses).
  - Things get tricky with multiple levels of inheritance.. you'd also be tempted to use
    type offsets for the type to deal with this, which would lead to slow switches, you'd really want
    a 0-based union index instead.
  - Instead, could be a special kind of struct that explicitly lists union members, which may now
    include scalars and any other type:
    struct foo = union { int, string, xyz, some_struct }
  - The tag is the type, no additional ident required.. in the case you want 2 of the same type in a
    union, you'll need to wrap in a struct first.
    - Like variant in C++, except supported by the language.
    - What about union members that don't need a value?
      - should at least allow the void type to have a union-nil?
      - and/or empty structs if there's multiple such values.
  - Construct with nested constructors, e.g. foo { 1 } that simply stores the value along with the union
    index.
  - deconstruct with a switch, or "is", resulting value being the union member without the type tag.
    - will have to see if changing the flow type of a variable to not just change the type but be
      a different stack slot is ok, since we can't always modify the original?
- For unions, being able to combine this with integer bitfields would be especially sweet, if you
  assume the type field is always declared as 8-bit, you can now make unions where several integers/bools
  are packed into the remaining 56 bits!
- One complication is the bitfield we use for structs to know where refs are.
  - We could be lazy: allocate slots so that the bits align, making for possibly larger than
      expected union values.
  - Alternatively, expand the representation, sticking it as a field in TIField is most elegant
    (but max 32 cases), or make the existing field an index into a byte array (any number of cases, max
    8 or 16 or whatever fields) which is probably safer.
    This lookup is currently only done for destruction of mixed ref/scalar struct vectors, and vector append/copy,
    since for single structs we codegen POP(REF)/INCREF per field, or emit bitmask as part of the
    IL_LV_WRITEREFV and IL_VFORELEMREF2S instructions which would now need to look up into the TI instead,
    which is somewhat expensive..
- see also: https://github.com/aardappel/lobster/discussions/242

- improvements to the new member/frame functionality:
  - bundle subsequent decls
  - how to do if frame_event: do_for_N_seconds
  - find more places to use it, samples etc

- continue vmcore experiment.

- Inline tocpp into codegen, see below.

- "C-style language to Lobster Cheat Sheet" could use improvements, and more about types.
  Also def for function values.

- move to more of a many-passes architecture to facility cleaning up further messes,
  in particular resolving generic types, and maybe some of the function checking.
  Could start by having a number of passes between parser and type-checker, and
  systematically pull steps from the typechecker into that, with the objective
  that the final typechecker pass only works on concrete fully specialized types.

- move function checking into typechecker.
  This is now mostly done.
  - Fix non-lexical ordering issues in GenericCall::TypeCheck
  - Make decision-making in GenericCall::TypeCheck more robust.
  - Further reduce whatever is happening in ParseFunctionCall
    - also merge with DynCall and Dot parsed elsewehere.
  - check that we're fixed all below:
    - the biggest issue is that it first selects on args, then on 1st arg type, it should be the other
      way around. Parser needs to stop trying to select Function based on args, and typechecker should
      first filter on type (important: foo.unknown should complain about unknown, not about foo because
      some completely unrelated type has an unknown defined on it).
      Possibly not separate Function on args in the first place. different scopes
      should have completely separate set of functions.
    - generally having all functions global is a big source of confusion, should have methods separate.
    - problematic error:
        error: no version of function `f` takes 0 arguments
      - where `f` is a method yet to be declared in the current class, but also used in other classes.
      - and even if it is already declared it gets confused, since strictly there's only versions with >0 args.
      really need to move decision on which function is being called to the type checker.
      possibly even store methods on a per type basis.
    - problematic error:
      test_worldmove.lobster(21): error: cannot define a variation of function set at a different scope level
      in:                 def set(p, s, e):
      (this with a `set` method somewhere on a class, and this set local to another function)
    - problematic error:
      cannot override built-in function `remove` with same (or less) arity
  before:
    - Move checking for functions/builtins/selfarg etc to type checker.
      This is quite hard, it requires reworking a lot of stuff:
      - all the withstack related functionality, which in turn requires not only calls and derefs to
        be generic, but also individual idents since they can become derefs.
      - there are still parsing decisions being made based on whether something could be a function,
        in particular calls without parens.
    - It would be better if we could leave the decision whether something is a builtin or a user
      defined function to the type checker, since that would allow user defined types to have
      a length function, or anything else that clashes with builtins.
      Problem is, we rely on deciding this in the parser for things like parsing lambda args,
      and optional things etc.
      Maybe if both are available, we could simply require that the user function corresponds to
      the builtin one in terms of these features, and otherwise error?
    - the parser deciding between a field or function upon x.y is very brittle, the moment someone adds a field
      called "length" anywhere, suddenly all calls to length() don't work anymore.
      Only way to fix this is to delay this decision until typechecking.
    - should overhaul ParseFunctionCall, it contains way too much special purpose logic that may
      clash with typechecking.
      - this would also allow defining methods with the same name as builtins, which is sorely needed.
      - after cleaning up parser, for every top level definition should mark from which file it comes,
        and then each use should make sure that file has been included in the current file, to avoid
        suprises when things are included independently.
      - if we can delay looking up the function to the type checker, then we can allow
        "functions as environments", e.g.
        def env(f):
            v := 1
            def m(): return v++
            f()
        env():
            for 10: print m()
            env():
                m()  // increments different variable!
        This is kinda like "with" or dynamic scope, and could benefit match.lobster, gui.lobster.
        The type checker already supports this, its just the parser lookup!
        Using this recursively will make it harder to optimize stack frame usage in the future,
        though neither match nor gui is properly recursive, it is all instantiated.
      - example of deciding between different methods going wrong:
        class foo:
            def f(): g(3)
            def g(n): print(n)
        class bar:
            def f(): g(3, 4)
            def g(n, m): print(n + " " + m)
        bar{}.f()
        bar{}.g(1, 2)
        foo{}.f()
        foo{}.g(1)
        error: "g" (1st argument) requires type: foo, got: int
      - can things like closures be parsed conservatively after a function call without knowing
        the function? It seems to already work for some calls:
        def foo(fun):
          fun() x: print x
      - SharedField can be removed, only needed in deciding how to parse x.y and x.y(
    - If we're NOT going to do the above, then some more uses of new GenericCall can
      already be made to specific calls in the parser.

- There's likely all sorts of uses of SubFunction that would be less buggy if Overload was used instead.
  - To find out, have to audit every use of it.

- error on `if a:` where `a` is non-nillable ref type?
  - same for `assert a`.
  - would make specialization more restrictive, but avoids errors while refactoring etc.

- this should not need an assert:
  var a = nil
  if not a:
      a = val {}
  (assert a).x

- This complains about `a` being nillable in the else branch:
    var a:string? = "a"
    if a:
        if seconds_elapsed():
            a = nil
        else:
            print a.substring(0, 1)
  If you switch the two branch blocks it works fine.
  The problem is that AssignFlowDemote for `a = nil` has to conservatively reset a's promotion to non-nil,
  which then also holds for the else branch. Same thing happens across switch cases.
  A real solution would be some kind of "pending demotions" scope around the whole inner-if that
  gets applied at the end of the inner-if. Meanwhile, the demotion still has to hold for any code
  in the same block as `a = nil`, so demotions should should be added to the flowstack also rather
  than only invalidating past promotions.
  For single block scopes like for/while it doesn't matter, but probably should use the same delayed
  demotion system for consistency.

- Since we compile on the fly, we can actually add a library like
  https://github.com/Celtoys/Remotery 2K*thing 
  https://github.com/wolfpld/tracy 4K*
  https://github.com/zeux/microprofile 400*
  https://optick.dev/ (free for commercial use, no opengl profiling) 2K*
  https://github.com/yse/easy_profiler 2K*
  https://github.com/google/orbit (sampling only) 2K*
  https://superluminal.eu/ (commercial, only pdb based)
  https://www.puredevsoftware.com/framepro/index.htm (commercial)
  http://www.radgametools.com/telemetry.htm (commercial)
  and insert an instrumented scope for every single compiled function conditionally when --profile
  is supplied or whatever, and get very real stats on what is using CPU (and opengl GPU).
  Additionally allow explicitly scoped blocks from Lobster.

- Would be nice to translate the code in https://craftinginterpreters.com/ to Lobster.
  It is a small amount of code: https://github.com/munificent/craftinginterpreters/tree/master/java/com/craftinginterpreters/lox
  Learning how to write a compile seems a frequent desire among Lobster users, and
  being able to do it alongside this great book would be a lot of fun.

- use this instead of the current lib for span? supposedly better than the std version:
  https://github.com/abseil/abseil-cpp/blob/master/absl/types/span.h

- Really need some better tools for flexible construction, see e.g.
  https://github.com/aardappel/lobster/pull/166
  One simple thing would be an actual constructor function, but this doesn't help with
  wanting to keep fields non-nil.
  It be nice to somehow allow field initializers to depend on prior field initializer
  args, but the problem is that this code runs before the object is contructed, so
  there is no obvious way to pass these values.
  The most flexible system would be a free-standing function that is able to take
  N construction args, and returns M values that must correspond to the uninit fields.
  Or actually, instead of M value, just contruct the object.
  Of course you can already write this manually:
  def new_dictionary(size): return dictionary { map(size): nil, size }
  So the question really is to a) make this syntactically more pleasing/standard/obvious,
  and b) disallow construction without this function since the map encodes an invariant.
  And disallow that, _except_ for in this construction function.
  Probably have it declared outside of a class to make it obvious it can't access
  fields/methods, maybe with a new "constructor" keyword instead of "def".
  Then just change constructor syntax to calls to these functions for any use
  outside this function.
  older:
    - Would be nice to have more powerful constructors.
      Current constructors eval the field defaults outside the context of the class, which is a
      nice way to avoid all the problems around partially constructed objects.
      And with nil-safety, we can't have any uninitialized fields being accessed.
      One idea would be to generate a constructor function from all initializers, which then can
      access other fields and methods. During type-checking of that function, the class would be
      marked as haveing N of its fields initialized, and any read of the remaining ones would error.
      That should in theory work with calling any functions thanks to flow analysis, but the
      problem is functions that have already been typechecked against the normal type, which would
      have to error or be specialized again.
      Even more extreme is to include that N in the type itself, such that a sub-typing relationship
      can be used, but that is a lot of complexity for the priviledge.
      And frankly creating more specializations just for this distinction doesn't sound great.
      Also we have some complex logic around tagged constructor args that would have to be wrapped
      into this generated function..

- set up oss-fuzz for Parser etc.

- split builtins into categories for helpfile

- always clone on specialization.
  - see CloneFunction: all these things should be moved to Overload?
    - true, but this doesn't save a lot of memory or make a ton of code
      more elegant, and actually a LOT of these vars get modified by specialization.

- (mortimersnerd) Type system: allow any struct of same set of fields to be converted to any other
  such struct?
  Goes a bit agains strong typing?

- instancing
  https://learnopengl.com/Advanced-OpenGL/Instancing
  or GL_ARB_multi_draw_indirect even more flexible.

- check that constant string caching works with e.g. FlatBufferBuilder?
    for(10) i:
        var s = "                           "
        s = write_int8_le(s, i, 'A' + i)
        print s
- It may be worth separating out strings from buffers, that way we can do zero-copy-alloc
  string views onto buffers which is really the ultimate way a language can do strings:
  https://twitter.com/wvo/status/1535311563992666112
  Thing is, the ideal view type would be
  struct string: s:buffer, offset:int, size:int
  and making all string functions take this struct may be troublesome?
  Can also make it heap allocated for now since these are still cheap since they're small & fixed size.
  Or could see if we can pack the view data into a single 64-bit quantity..
  - too limiting probably, even with a global table of buffers
  - can do a page-aligned arena of buffers to have the view be a single offset+len into that,
    but then memory can't move.. and mmap based allocation uses too much address space
    and page aligned not great for small strings :)
  If we go this route, should see if those views can be given a type for super ergonomic byte
  buffer read/write instead of write_int8_le and similar functions.
  Likely, we'd want buffers to never be able to shrink, since that would possibly make every
  string access a runtime error if its now out of bounds.
  buffer type would convert to string automatically, so that mostly it doesn't need to be
  accepted specifically anywhere.
  Another issue is the pervasive use of strvnt()/data(), which would now now need an optional copy
  again. One way to solve that is to allow an implicit string to buffer conversion that
  copies if the string doesn't address the whole buffer, that way these builtins (like imgui)
  can demand a buffer for their label? A bit odd to use buffer that way though.
  Instead, for most functions can do the swap terminator trick on these buffers.
  The other most frequent op is string concatenation, would be fun if that was optimized?
  e.g. a + b, if a spans a whole buffer, it should be legal to actually place b into
  this buffer, making it possibly an alloc-free operation.
  Problem is, people have to structure their code explicitly around passing in the LHS as an
  arg to any string producing operations.
  Could have specialized versions of some string producing ops, i.e. a + 1 could be
  compiled to generate the int directly in a's buffer.
  It is somewhat magical, in that if you created a buffer for say serializing a file, then
  wanted to print the string you just serialized at the end, and if the printing did some
  concatenation you'd end up with extra data in the buffer, though that is fairly contrived,
  since you'd have to explictly do buffer.substring to produce that problem.

- we should add constant size arrays.
  they would almost be identical to structs: allocated in-line in parent, copied rather
  than referenced, and help building low cost datatypes.
  We could even make them piggy-back on structs, as essentially a float[4] is just a
  struct with 4 float fields that you can also index over. And we already allow
  indexing on same-type structs?

- Type aliases, in particular for use with int/float/string, to distinguish them from
  other uses of the same type.
  They would decay to their base type much like enums, but would need casts to avoid
  a type error the other direction.
  They would differ from wrapping in a struct, since by default a struct as a whole
  is not entirely compatible with the base element type.. though maybe it should be?
  Would cause more specializations, since you'd need to perculated the type alias
  to get the full range of type checking from them.
  Would make it more important to merge specializations on a bytecode level?

- Should we specialize own vs borrow on a per string constant basis?

- Would it be possible to allow overloading of built-ins even with same number of args?
  https://github.com/aardappel/lobster/issues/145

- Fix FIXME in Break::Generate

- `sum` and some other std functions have `let init = 0` to work around the int/float constant warning.
  Can we do something better here?

- One not so nice thing about `::` to create a type scope is that it forces you to declare the type, e.g.
  hof() x: ..       // don't have to declare type of X, derived from `hof` arg.
  hof() (x::X): ..  // Must declare type.
  hof() (x::): ..   // Type inferred much like above
  hof() (::): ..    // We're not going to use `x`, so should this be possible?
  hof() (_::): ..   // Or just this as a convention.
  Why does this matter? Well this style is awesome for DSLs, where `X` basically brings
  a whole bunch of methods in scope that can be used to construct or render something
  in a very lightweight fashion, where the context (`X`) is implicit.
  `hof` here may be something you want to nest, and the repeated decl of `X` would be unwelcome.
  See: Kotlin, that made a very cool feature out of this:
  https://kotlinlang.org/docs/lambdas.html#function-types

- "guard" is a feature to promote early-out programming style, but more deeply it can also
  be seen as analogous to Icon/ProLog sequence of expressions that can fail.
  It treats a sequence of Lobster statements/exps and says that an exp may fail (0 results)
  thus the statements/exps after it should not be executed.
  But what if you did the same for "success"" of more than 1 result?
  Lobster already has the ability for a function to "generate" results as a HOF and thus
  look like a for loop, which can use a ProLog "cut" operation across function boundaries
  with return, so we can already do this.
  But much like "guard" is a syntax-only feature, you can imagine a flattened version of iteration
  that relies on a HOF or for underneath:
  stat1
  each a = foo(10)
  stat2
  Where "each" is like a "let", except it will iterate the subsequent statements 0..N based
  the values supplied by its initializer.
  "foo" would be a 2-arg HOF where is 2nd arg is the function value implicitly passed, so
  it is equivalent to:
  stat1
  foo(10) a:
    stat2
  If the initializer is not a HOF it would default to the args passed to for, i.e. you could
  write "each a = 10" or whatever.
  "guard" is a special case of this, since you could implement guard as "each _ = boolean_exp"
  I guess additionally "each" doesn't have an optional else block, so the distinction is still
  useful, besides the clear naming.

- natgen refactor
  - inline tocpp into codegen, removing bytecode entirely.
    - will likely make all refactorings below easier!
    - this stops us from being able to ship bytecode in a pak as a quick way to distribute programs
      without building C++.. people have to now either ship C output or source.
    - makes it easier to output C that looks like normal C, which would benefit libtcc codegen.
  - start moving vmops into tocpp for all simple ops.
  - most access to local arrays still thru memory, clearly alias analysis failing.
    - split up arrays into individual vars where possible.
    - ideally then make sure these vars never "overlap" when used with structs, so they can
      be properly register allocated.
    - make args into actual C++ args?
      - this could help not having to pass parent pointers to regs which could help optimisation.
  - somehow remove temp_lval
  - make all builtin calls direct
  - move more stuff into the epilogue.
  - de-inline vm ops that are big: check in disassembly
  - NO RUNTIME STACKTRACES!
  - shrink fvars array in VM
  - can finally remove exceptions? could instead execute a return from -3 or whatever.
    - the big challenge is doing that for errors.
      - this may be easier after builtins are inlined.
  - Now that all bytecode goes to native gen, make bytecode more specific to it.
  - threading appears broken (sequential?)
  - remove next_call_target
  - test/enable
    - --cpp mode for mac/ios
  - start regs sp at end to access top slightly more optimally?
    - need to flip all struct order etc.
  - reduce use of ElemType.
  - once things are faster, test with https://github.com/kostya/benchmarks/

- Add to docs:
  - As static as possible memory management: https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-908.pdf
  - V "autofree"
  - Serene: https://jamiemoschella.com/serene-ideas/mkdocs/site/index.html
  - Koka/Perceus: https://www.microsoft.com/en-us/research/publication/perceus-garbage-free-reference-counting-with-reuse/
- docs only show switch used as exp

- should really have a way to test errors.

- Do better stats on specialization code bloat, and implement a byte-code level merging pass.
  - would first need to make jumps relative encoded.

- stefandd: DLL builtins loading.
  - make sure to put in checks for debug/compiled/32-bit mode, and maybe some other compatibility checks
  - maybe use __TIMESTAMP__ of vmdata.h as version?

- Further cleanup of THROW_OR_ABORT
  - It should really never be used from inside the VM, but because its used in lex/parse/..
    it still can do when calling compile_run_code or parse_data, causing a terminate on Linux.
    - instead, make these do a locally contained exception.
- The hardest problem in fully removing exception handling is things like vector bound checking,
  which, if it were to have to be handled like an error return, would cause almost every function
  to need a check after its call.
  - Still worth trying, it may be that this branch being always false is actually very cheap.
    - Can stick an error bool as first field in VM.
  - Another approach is to have a class of runtime errors that always aborts the current program.
    That is undesirable for a scripting language (though only if it must safely be able to run
    externally authored programs).
    Languages with bounds checking like Rust do this too, and are not usable as a "scripting"
    language as such.
    So maybe its time to recognize that Lobster is that kind of language too.
    There are probably other things that make Lobster unsuitable for untrusted "scripts" anyway.
    Actually, can keep it semi scriptable by allowing the "host" to set a call-back on fatal
    runtime error, and they can still choose to throw an exception or otherwise terminate the
    VM.

- Add this to replace any use of the terrible std:: hashing functionality:
  https://github.com/martinus/robin-hood-hashing

  Also would be nice to have a good hash-map as part of the language, to compliment the
  simplistic binary_search.
  If we do, would be nice to use a technique like https://github.com/martinus/unordered_dense
  and have it be based on the existing vector type (either as "subtype" or it owns a vector),
  that way all the vector ops we have can be reused as-is.
  Could cheap-out and add one as a resource, but that would make retrieved values have no
  type.
  Maybe allow resources to have a type parameter?
  Add a type cast? :)
  Or add a proper map type to the language, probably not that hard? That would make it easier
  to optimize for all sorts of types.
  Since this is a C++ template, could do a map from Value->Value, but that would forego some of
  the optimisations this has specifically for string keys etc.
  Also, int3/float3 can be very useful as keys and would want to support.
  dictionary.lobster is already nicely generic if constant speed is not too important.

- stefandd: multiple assign doesn't work on fields.

- Fix `is`, see https://github.com/aardappel/lobster/issues/99

- See if audio works again under emscripten:
  https://github.com/emscripten-ports/SDL2/commit/865eaddffed50dbd13e6564c3f73902472cf74e8

- If we want a replacement for SDLMixer:
  https://miniaud.io/
  - 3D spatialization built-in.
  - supports ogg thru stb_vorbis
  https://solhsa.com/soloud/
  - also 3D built-in.
  - has a ton of cool features.

- enums
  - mortimersnerd: get min/max
  - use namespaces
    - remove keywords?
  - iterate them? return a vector of all values?
  - convert to string.

- jpp: support labels in function calls just like with constructors.

- There is no way to pass a [sub] to a [super] since that break safety if a different sub
  is inserted that way. But this is really restrictive, because once you have a [sub] you can
  only get around this by copying the vector: map(subv) () -> super: _
  There is one case where passing to a [super] is safe, if that destination is const.
  It would be nice to have a way to annotate that for functions, or infer it.
  We currently have this hard-coded for builtins like append() using NF_CONST.
  - making this worse is that "this" doesn't specialize, see settlement.lobster/take_damage
  To be more precise, it is safe if the dest can't ever mutate (is const, and doesn't create
  aliases that could mutate in the future) OR if the src has a refc of 1 (a constructor), since
  in this case the dest will be the only alias ever.

- it's possible to bypass variable initialization with forward calls which will crash.

- We are probably not checking if T every gets bound to a scalar in T?, in fact are we doing
  this for regular V_VAR?

- lobster should explicit recursion? https://github.com/google/flatbuffers/pull/6364
  many uses of recursion are problematic in terms of stack use, the user should really be
  explicitly aware of them, and they should be easy to find in a program.

- it be really easy to bring full "any" back for builtin functions, and mixed type varargs
  at the same time by prefixing each value on the stack by a ti value, and possibly a length.
  what is this useful for?
  - more efficient print and to string?
  - formatted printing?
  - serialization?

- jpp: remove can't use named function as value restriction.

- jpp: would be good to be able to overload print/string for own types.

- jpp: print without newline.

- jpp: not being able to do arbitrary computation to initialize a field is pretty limiting.
  someday should maybe support user defined constructors?

- jpp: add "continue"?

- add a debug (or dbg) statement analogous to asssert, like:
  https://github.com/sharkdp/dbg-macro
  also improve assert output

- jcorbin: improved random number generation:
  - swappable generators such as xorshift, pcg32/64, and even just a generic lcg
  - especially so since insatiable random generators (to get multiple
    independent streams) would be great in addition to / instead of a shared
    global generator

- NEWVEC can defeat the STACKMARGIN check if called with sufficient args.

- Expand ConstVal and the optimizer. It should be implemented for every node.
  - Actually probably doesn't need to be implemented for `if` etc, since it already
    has special purpose code for this.
  - also add constant propagation.

- jg/jcorbin: should allow function values to be other than just variables, any exp.
  currently not even `f()` works if `f` is a member variable.
  _ as function value doesn't even work even though explicit var does for loop.
  maybe this feature is easier to introduce after refactoring what happens in the parser.

- jg: it's pretty easy to define a function value with an escaping free variable that gets
  caught neither at compile time nor at runtime.
  We need to somehow protect users expecting closures from this, yet we don't want to blanket
  forbid free variables when something becomes a dynamic function value, since there are plenty
  of useful cases of accessing top level variables etc.
  Maybe somehow tie the scope of free variables to the function type?

- remove restrictions or make clearer errors:
  - call on function value must be single var, not member
  - cannot derive function value from named function.

- create xy { "a", "b" } without explicit string specialization gives:
  error: "constructor" (1st argument) requires type "T", got: "string"
  should probably ask for an explicit specialization instead.

- General order of typechecking is:
  * child TT
  * child LT adjust
  * subtype coercion
  This can be problematic in some cases, what really needs to happen is:
  * child TT
  * child LT adjust for coercion
  * subtype coercion
  * child LT adjust for recipient
  This is already done manually in a few places, but would be good to do more consistently.
  Recent example:
  def multirettyped() -> float, string: return 1, "a"
  This first causes a LT adjust on the MultiReturn, which the can't have coercion applied to it
  anymore in Subtype (see end of TypeCheck::Return).
  Also, maybe have the case where LT adjust does nothing (e.g. for integer) then subtype coercion
  to e.g. string suddenly needs a different LT than the initial TT.

- Builtin overload resolution could be simplified:
  https://github.com/aardappel/lobster/issues/89

- Explicit genericity for functions.
  - overload resolution still doesn't use giventypes.
  - if we had T() as a cast, we could fix the enum type problem in gui_multiselect.
    - that is yet another form of function call in the parser.. better first refactor that.
  - weighted_pick: being able to write "T is float" would be cool.
  - See typetest.lobster: Explicit generic mixed with dynamic dispatch doesn't seem to work.
  - Generics for function types? See use of R in std.
  - currently can't specialize with itself:
    class X = Y<Y,..>
    Useful with e.g. astar_node that doesn't need new fields.
    Workaround is to subclass instead.
  - Also using nested classes might not work well with generics since we resolved in non-nested
    fashion field types at the beginning of the type checker.

- kriskowal: maybe replace gl.button string with an enum.

- docs: explain about unbound variables, and what causes:
  type variable does not have field: size

- Add a "run as DLL" mode for --cpp.
  This would, if Lobster can find an installed C++ compiler, compile the compiled code to a DLL
  to be loaded straight into the running program, as a faster alternative to TCC.
  Can do this by exporting the VM ops as function pointers to the DLL, but that would likely not
  be much faster than TCC mode.
  Instead, it would have to compile also the VM ops + vmdata.h/.cpp etc into the DLL.
  That could be somewhat slow at -O2 for larger programs, but worth it in many cases.
  This would give the same speed as natively compiled mode in -O2, and the user could even choose
  to ship this DLL!
  Also can alternatively run with -O1 / -Os for different tradeoffs in startup & running speed.
  Alternatively, if we want to avoid the linker and use it with the actual LLVM JIT, we
  could have clang generate bitcode and feed that to the JIT:
  https://weliveindetail.github.io/blog/post/2017/07/25/compile-with-clang-at-runtime-simple.html
  Though having to provide C++-mangled externs for the JIT for everything the compiled code
  touches likely not fun.

- Since the JIT, stack overflows now just blow the native stack, since function calling uses
  the native stack. This will be hard to fix since we don't know the size of the native stack.
  We may well have to accept this as "normal behavior" since Lobster is now a native (not
  "managed") programming language? You get:

  The terminal process "bin\lobster.exe infrecurse.lobster" terminated with exit code: 3221225477.

- Would be good to finally make SDL modular, and get rid of that silly main-redef
  There's this: https://wiki.libsdl.org/SDL_SetMainReady
  But elsewhere it still claims that things may fail or give you bad error messages if not used
  https://stackoverflow.com/questions/34079288/im-using-the-sdl-functions-without-the-sdl-main-be-defined-is-that-fine

- kriskowal: a non-allocating version of copy() with a second destination arg.

- kriskowal: might be fun to have gl.cube and other simple 3d primitives, for quick prototyping?

- this is interesting for the variety in graphics it allows:
  http://wiki.winamp.com/wiki/MilkDrop_Preset_Authoring
  would be cool to do a Lobster example of it
  would need 2 offscreen buffers larger than the screen, the older one blended into the current one
  (with zoom/scale), then the current one shrunk into the screen

- if you write def(): return 1, it appears as a function of 0 return values since it works the
  same as other anonymous blocks (the return actually goes to the enclosing function).
  This is probably unexpected, but how to do this better?
  Maybe specialized warning for this case since it makes no sense?

- should really support proper tail calls, e.g. https://www.lua.org/pil/6.3.html
  Once "return" is gets compiled such that it jumps to its own stack unwinding code, there
  can be a version where there's additionally a function value on the stack that gets called on
  the "return values" at the end of unwinding.
  - can reduce some of the downsides we have in the typechecker for recursive functions (which
    can be avoided to be marked recursive).
  - can do simple state machines.
  - must check that the function being called does not use free variables of the function that
    just returned!
    - as such, maybe tail calls are better off as explicit syntactical feature, since optimizing
      unsuspecting non-recursive calls into tail calls is not actually faster.
      - we don't want people requiring a tail call that then silently doesn't become one because
        of free variables.
      - especially since it avoid the function being inlined, and we don't that arbitrarily making
        things non-tail calls either.
  - can go even further, and can make this into a feature that emulates co-routines?
    Instead of at the end of unwind calling the function, it can be regarded as a little struct
    return value (a closure that doesn't close over anything), which can be called at any time
    later!
    - problem is that doesn't give a way to resume with an arg?
      maybe a way to overwrite any arg would be simplest?
      resume with an arg is much less frequent than returning on yield, so maybe not a big deal.
    - also work with anonymous functions being tail called, maybe with auto parameter passing?
    See: https://github.com/aardappel/lobster/issues/100
  - imagine if you could push multiple of such closures, to be called in sequence, potentially
    consuming values from previous such calls?
    this way you could make the recursive quicksort non-recursive, by returning 2 quicksort calls
    and 1 append_it_all call. though of course this still uses unbounded stack memory, just less so.

- New co-routines with some of the ideas above or in https://github.com/aardappel/lobster/issues/100

- jcorbin: a basis_spline equivalent of cardinal_spline

- CMake LTO:
  - supported in 3.9:
    https://stackoverflow.com/questions/31355692/how-do-i-enable-link-time-optimization-lto-with-cmake
  - can replace the current LTO setting for CMake which apparently don't work on mac.
- Move all platforms to CMake
  - Support in VS seems good now, worth trying.
  - Once we have this, we can also modularize some of the larger dependencies:
    - add them via git submodule.
    - make building them in CMake conditional on them existing.
      https://cmake.org/cmake/help/v3.5/command/find_file.html
    - now someone can use git submodule to decide if they want a lean or full fat Lobster!
      There are ways to init and de-init individual submodules!
      You can even go further: have CMake control which submodules are installed:
      https://cliutils.gitlab.io/modern-cmake/chapters/projects/submodule.html
    - We can now add new optional modules:
      - Physics engine (see below for options).
    - We can now may make existing things optional:
      - imgui
      - box2d/liquidfun
    - We can even make the engine a modular add-on to Lobster itself!
      - create easy way to build Lobster as console-only language.
        -> this already available for Linux/CMake: just turn off the LOBSTER_ENGINE option.
  - Do it all with VCPKG?
    - that is actually not even that necessary, mostly useful if you have many projects
      that share these dependencies.
- Upgrade CI to more recent compilers, to support e.g. to_chars.

- stack & variable access is becoming a bottleneck in native backends, should think of a
  way such that they can easily be swapped out for native locals when possible.

- default/tagged args for functions.

- consider adding optional {}.. it really seems to bother people.
  make it such you can only use one style per file

- run coverage to see where more tests are needed.

- Would be nice to merge Texture and OwnedTexture, since they are generally owned by Lobster
  code.. exceptions are Textured and SwitchToFrameBuffer where we have weak references to
  Texture.. this could be cleaned up by making these locations do inc/decref, but that
  means a Resource should hold a ref to LResource to get to refc, and gltexture.cpp now relies
  on Lobster refcounting etc.
  Or, give Resource its own refc, such that if LResource drops to 0 it only decrements Resource.

- Remove exceptions completely by making each function call always check for a target function,
  and then make runtime errors use the same mechanism
  - fun way to make this fast: if an exception occurs, decrement the return_ip field in all
    stackframes by N, and insert an exit function jump after each call, and before the regular
    continuation. Then the code can unwind without conditionals.
    Though not easy to do in C++/Wasm backend mode.
  - alternatively: each call supplies 2 return ips, the regular and error paths.

- do more inlining:
  - mark certain functions as un-inlinable.
  - for the remainder, compute a) the cumulative size if everything beneath it got inlined,
    then b) the number of callers
  - now based on this cumulative number for the root function, determine a maximum blow-up
    amount that is desirable. Then mark as not in-lineable the function that would make the
    biggest reduction in code size according to a*b. Recompute sizes of parents.
    Repeat until desired code size is reached.
  - now blindly inline absolutely everything else that remains.
  - for programs that don't contain any combinatorial patterns, this will allow everything
    to be inline.
  - need to see what consequences this has for making the lifetimes of variables longer.

- Replacing the use for Terminal() in the type checker by a NORETURN type would simplify the
  code and probably allow for a larger variety of code structures utilizing this.

- Good errors are increasingly an important programming language feature, should at some point
  invest in an overhaul. See Rust and Elm in particular.
  https://blog.rust-lang.org/2016/08/10/Shape-of-errors-to-come.html
  https://elm-lang.org/news/the-syntax-cliff
  - Make line refs ranges rather than locations.
  - Allow printing of not just one but multiple references to what errors refer to.
  - Somehow collect stats on what errors occur a lot, and add more detail to them.

- Should add template arg types also to regular functions.
  - an example is gui_multiselect called with enum type for selected.

- SRGB support:
  - Update imgui once this merges: https://github.com/ocornut/imgui/pull/2943

- Optimize out variables that are not used.
  This in particular will be good for vec/color.lobster that create a lot of globals,
  also means they don't show up in stack traces / debug windows etc.
  and can reduce function usage as well, if they're in initializers

- jacob: something to allow HOFs that need to undo state, i.e. a non-local return thru
    var state = 0.0
    def translate(dx, body):
        state += dx
        body()
        state -= dx
  Is going to produce hard to understand bugs, yet also natural to write code this way.
  Built-ins like gl.translate also suffer from this issue.
  https://github.com/aardappel/lobster/issues/93
  Solutions:
  - a "defer" statement. Simple, but requires the programmer to remember to use it, does not
    stop the above natural code being written.
  - Some form of RAII. That is even more complicated, and still requires the programmer to
    be smart about it.
  - A way to annotate the body() call as not allowed to be returned out of. This is really
    simple since this can all be detected statically, doesn't require any runtime support.
    At least it stops the user of this code making mistakes, but still requires the
    programmer to know when to use it.
    Also it would be a bit weird if some global error function can't be called from within
    a translate.. (actually could still allow `return from program`)
  - Just leave it as is. Prefer not to write HOFs that modify state, and if they do, well,
    the user needs to be aware changes don't get undone with non-local returns.

- FlatBuffers implementation:
  - once we have mixed scalar/ref: make accessor handles into structs.
  - Make builder offset struct into specialized structs for the type? Maybe not necessary?

- It often crashes in creating the stack trace when values are corrupt.
  If this results in another error, it perculates up the exception, but no such help for asserts.
  - Would be good to print to stack trace incrementally rather than accumulating in a string first,
    with some kind of callback? so output can happen before the crash.
  - Make reading values more robust.
    - If VM is in an "error" state, ignore any bad values and just return empty defaults.
      - this has to sadly be done at every callsite since Error is not expected to return.

- think about special casing parsing of if/while/for, that way some crazy syntax features can be
  reduced
  - if can gain an elseif
  - if's typical ambiguity with if x + f(): in terms of the closure can now be default to
    the close being part of the if?
  - while can be the sole user of exp as closure..
    - also can fix issues with lifetimes
  - for can lose the brackets?
  - what features could we remove from function calling that are unnecessary?
    - maybe _ args?
  - besides the syntax, the question is should it also change the bodies from
    functions into inlined blocks?
    - pro: simplifies a lot of code in the type checker, reduces pressure on
      inlining, makes ast more readable etc.
    - con: some logic related to functions will need to be duplicated for blocks.
    on the whole I think its worth it, but do it seperate from syntax.
    probably while condition can be made into a non-function first.
  - can consider also making higher order functions introduce the lambda with a keyword to
    make it all more parsable.
    map xs do x: body
    map x in xs: body  // Python-esque, sadly in an odd order.
  - more discussion in: https://github.com/aardappel/lobster/issues/56
    options:
    - if a ( follows a function call, it must be without space, and thus it effectively forces
      there to be two of them.
    - allow function to declare that they take their first are without ()
      - now spacing doesn't matter
      - but we don't even want to allow `for (` necessarily.

- increase abilities of "break"
  - break out of multiple loops.
  - break out of loops in higher order functions.
    - that can be shown the be safe when the lambda the break sits in is guaranteed inlined
    - the problem is the semantics: you transfer control to the end of the loop inside the
      HOF, and you don't necessarily know what that does. Though in many cases it will work,
      e.g. break inside a "map" will just return a shorter list.

- Now that the language is always 64-bit:
  - can further improve type simplicity by:
    - Would be nice to move everything to using 64-bit, but this is hampered by the STL on
      32-bit platforms wanting size_t everywhere, which means most values still needing to
      be at least ssize_t not require casts, which still requires casts between it and any
      always-64-bit values, limiting the amount of cleanup you can do.
      There is some of this (see iint and ssize_t in tools.h), but converting more code
      only makes sense once we can drop 32-bit platforms entirely.
      See when all compilers support this to experiment with it?
      https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1227r2.html
    - change bytecode from int to LEB. this will make it more compact, though mildly slower
      to read. would solve issues with 64-bit contants etc. would read into iint or int64_t,
      depending. Can still hard-code instruction into 16-bit. Or make it a 16-bit LEB?
  - Can think of features that would allow use of smaller sizes as opt-in.
    - Should definitely add support for 8/16/32-bit int arrays and maybe struct fields.
    - Maybe allow special structs that pack multiple things in a single 64-bit value? :)
      - or you could introduce bit-fields, essentially: multiple fields that share the same
        64-bit struct entry.

- remove V_NIL from elemtypes and ElemTypeS, no users need this information, in fact all are
  working around it.
  - Also maybe replace uses that just want to know if its a ref or not by a table that lists
    all refs. could be two lists for nil and non-nil?
  - For vectors can just stick a bool in TypeInfo to speed up this case?
    - does its type-info even need vector wrapped?

- remove or bound LT_ANY, it makes checks for keep/borrow fragile and can perculate.
  - check for any == LT_KEEP etc, since != LT_BORROW (and vice versa) is safer

- we could try an do limited support for indexing [] in flow sensitive typing, e.g. just for
  constants and variable indices.
  - Any write to the vector should invalidate all indices
  - Any write to a variable used as an index would invalidate that index
- A more conservative mode for both flow-upgrades and borrows.
  The current algorithm is "optimistic" in that it doesn't detect all forms of aliasing.
  This works well in "real" code as these upgrades/borrows are typically short lived, and
  programmers tend to not access the same data over unrelated aliases.
  However, if we want to be fully sound even just as a check, it be interesting to see what
  is required for it to be impossible to subvert.
  - 1. Aliasing: it will always be possible to obtain two refs to the same data structure
    though independent and complex code that the compiler can't know refer to the same
    object. This means that writes to any type T must invalidate upgrades/borrows of any
    such types, even if under different idents/paths.
    Not unlike C++ compilers that reload array values into regs whenever a write to
    a similar array happens.
  - 2. Track all possible VM decrefs in the type system. We currently do assigns, but if
    we allow array indexing in the path (such as for borrows), we must also track vector
    functions like pop as a write that invalidates anything in that vector.
  - 3. Function call reuse. We currently re-apply non-local returns on a reuse, but not
    writes. Since we already track free variables, we could simply mark free variables
    written to, and invalidate everything they touch.. that is overly conservative, maybe
    a more exact system can be made.
  The above will generate more issues in code when turned on:
  - For flow upgrades, this can be solved with:
    - You could actually introduce a new hidden variable for each upgrade for the cases
      above where the upgrade gets invalidated due to possible aliasing. This would be
      inefficient because it would introduce a runtime refc++, but if the aliasing is real
      it will not delete the object.
      This of course should not be done for regular invalidations over the same var, which
      are intentional.
    - Alternatively, just let the error happen and the programmer has to re-establish the upgrade.
      This is a bit random, but should generally be super rare.
  - For borrows:
    - Since we want to keep borrowing automatic, it be nice if it could be downgraded to a
      keep automatically in only the cases where alias-invalidates happen. That would
      generally be easy and cheap, the only complication being with code that has already
      been type-checked againt that borrow, so we'd likely need a more indirect representation.
    - Could allow it to just be an error, since likely it rarely happens. If it does
      happen it may be a difficult error, but the programmer likely knows they are doing
      some tricky aliasing they may want to simplify?
    - Could allow more explicit borrow annotations.
  If we go this route, should first unify flow upgrades and borrows more, and e.g. allow
  Indexing also in upgrades, and track writes to the indexed expression etc.
  Frankly though, the above is a LOT of complexity, for something that really doesn't ever
  happen.
  Existing examples.
    - fix this:
        class A
        class B
        let b:B
        class A:
            x = "a"
            def ov():
                // overwriting "b.a" is all cool.
                b.a = A {}
            def sec():
                ov()
                // oops, this A has been deallocated.
                x = "b"
        class B:
            a = A {}
            def inb():
                // this creates a borrow on "this.a", but not on "b.a"
                a.sec()
        let b:B = B {}
        b.inb()
        /* 
        essentially, every time X.Y gets borrowed against and X was defined (arg or local)
        thru Z which is an active item in the borrow stack, Z.Y must also be added.
        but adding two stack items for one access doesn't work since the lifetime value only refers to one of them.
        Alternatively, CheckLvalBorrowed must check these on the fly but that is likely slower and more complicated.
        */
    - Detect this case:
        class Test:
            t:Test?
        var a:Test? = Test { Test { Test { Test { nil } } } }
        var c:Test? = a
        def f(b):
            c.t = nil
            print b
        if a.t and a.t.t:
            f(a.t.t)
      - having final/const fields may help reduce the cases where this is an issue.
    - see also: https://nim-lang.org/docs/manual_experimental.html#view-types

- For certain use cases, having "atoms" is a nice language feature, being able to specify
  undeclared identifiers that map to a unique set of integers.
  - Could be with a special prefix, such $foo or #foo
    - Possibly also allowing $'foo bar' to allow characters outside the ident range.
  - Would typically map to integers 0.., such that they work well with switch and have
    cheap lookup back to strings.
    - Means that they are only suitable for unique ids within a running program, not storage.
    - For storage you'd use the associated string.
    - Could also have an associated hash.
      - Would be cool if the value was directly a hash itself, if it were possible to guarantee
        somehow these values can be given unique unchanging hashes even when the set changes
        (such that they can be used for storage), but that seems.. impossible?
    - With 64-bit integers, an alternative design is to only allow lowercase, underscore, and
      a few others for a 5-bit number, allowing max 12 char identifier unique IDs (or with uppercase
      and numbers in 6-bit for max 10 chars).
      This gives uniqueness without hashing!
      Though frankly we already support 8 inside a character constant, so this would not add much
      to the current functionality.

- improve docs.
  - better "why should I want this language" intro rather than just a list of features.
  - maybe more of a document that is meant to show the best of the language, with
    examples, kind of like whats on the home page but more extensive.
  - have selectable examples like e.g. https://dlang.org/ https://ziglang.org/
    https://gobyexample.com/
  - redo philosophy doc.

- imgui additions:
  - File Selector:
    https://github.com/dfranx/ImFileDialog

- We support implicit this.member in multi-assign, but not explicit.
  See mretfields test.

- we should support e.g.
    import vec
    struct mat2x2<T> : xyzw<T>
    struct mat2x2_f = mat2x2<float>
    print mat2x2_f { 1.0,  1.0,  1.0,  1.0 } - mat2x2_f { 2.0,  2.0,  2.0,  2.0 }

- Do special purpose codegen for sequences of string concat with I2S etc.
  See GenConcatOp.
- Also, does sit make sense to allow += to modify strings in place?
  This is different semantics from += generally, but would be very nice to have.
  And combined with the above feature s += a + b can also be alloc-less.
  And then same for vectors?

- LIFETIME related TODO. Initial version exists, what is needed to make it better?
  - AssignList with instance variables probably doesn't work.
  - on calls like qsort([..]) the xs arg will be KEEP, but the recursive call will be borrow,
    so now you end up with 2 specializations.
  - split up incref/decref in VM for needing nil check and not, since we have this information
  - improvements to compile time lifetime analysis for reference counting.
    - things like "while n: ..." (see astar) are a source of unnecessary inc/dec
      see While::TypeCheck
    - make indexing and for do LT_KEEP and all-element borrow respectively.
      (see notes on sound lifetimes)
    - need to track last use of variable, so that the variable can turn from own->borrow there
      and potentially pass on the value for free.
      - we already do this as a special case for "return var".
      - another special case we should do: last lexical use of a var that has never been used
        as a free variable, thus deals with the exceptions below.
      - would at some point be great to do this more general:
      - ensure that this deals with last use in both if branches, or in a for loop (no last use).
      - needs to happen during TT because free vars in calls can be in non-source code order.
        - this makes it hard to detect the last use when it happens.
          - can lift ownership checking into seperate pass, possibly with duplication.
          - or can do an approximation, track last lexical use in parser, and only allow it
            to straddle known anonymous functions, such as if/while/for?
          - or, count the number of uses in parser, so TC can recognize last use even if out of
            order.
            - though this still doesn't take care of freevar in function called twice
      - may need a way to allow programmer to force a function argument to LT_KEEP as this is
        an easy way to fix assign while borrowed errors
      - or, for assign while borrowed, could "cache" these errors, and only issue them
        if a later use is found.
        - but it can be borrowed in all sorts of ways so this is also not an exact science.
      - or, for owned variables (with no refcount) where recip wants to own, allow ownership to
        transfer, but mark variable as dead so any further uses can be errors.
    - go thru an AST dump and check that where lifetime changes happen makes sense.
    - somehow get rid of ownedvars in FUNSTART. generally clean up function calling.
  - could omit the check for refc==1 at end of scope if we know variable has never had a
    refc inc/dec statically.
  - add language features that make use of this new system:
  - allow variables/fields/types? to be annotated as single owner, such that these can also
    lose their reference count (but stay heap allocated). Instead if incref they error.
  - optimize other remaining/related features.
  - should really centrally organize the concept of const vs owner vs refc, since besides for
    structs, will need these concepts for strings/vectors as well (will especially be
    nice to separate out the default const string from niche mutable use). We also have const/var
    variables. We were also thinking about mut argument annotations which would still also be nice
    being able to say an arg is mut without specifying the type.
  - Code like this complains about a being modified while borrowed:
        import imgui
        class A:
            s = "hi"
        var a = A {}
        im_treenode(a.s):
            a = A {}
    This could be avoided if im_treenode was forced to be specialized with own instead of borrow,
    but to know this, we'd somehow need to know its going to get assigned to.
    That, or always use own for functions instead of specializing, which would make the whole
    system more robust (and reduce the amount of specializations), but would probably increase
    the amount of runtime refc a lot.. something to be measured.

- add to imgui functionality:
  - logging
    - everything that currently goes to LOG
    - specific logging for variables not in global scope: show a list of key/value.
    - or simpler: can show all log variables!
    - additionally: a way to log not just a string but a data structure that can be inspected.
      This would go a long way to not having a proper debugger, extend the reach of print
      debugging, basically.
      Have a way for these log statements to not cost anything when a debugging UI is disabled
      so it can be left in the code for longer
  - docking branch: can allow e.g. debug window to be external.
  - more engine stats!
    - some basic profiling segments of code?
    - drawcalls? triangles?
  - add screenshot & link to imgui page?

- A way to load a DLL/so containing a built-in function extension, so larger
  libraries don't need to be part of the base Lobster, and people can add their own
  without having to re-build lobster itself.
  Would work best if these are passed on the command-line (or in a cfg file) given
  that these definitions are needed to parse a file, though you'd be ok to start
  parsing a file and defs becoming available half-way.
  Would also need to be stored in a bytecode file in that case.

- Something like Python C-types: ability to call any DLL/so function without explicit
  bindings.

- Python struct create: printf for binary https://docs.python.org/2/library/struct.html

- Built-in dictionary type?

- For fun: follow along https://github.com/kanaka/mal/blob/master/process/guide.md

- Would be useful to typecheck top-level named functions that have a full type signature
  and haven't been typechecked at the end of type-checking, to get any type errors they
  may contain earlier.
  - Have to be careful that it is still seen as dead code by the codegen, and not
    contribute to any use-count for inlining by the optimizer etc.

- Should refactor for size of files.. typechech.h is getting unwieldy.
  Can maybe pull out some lifetime stuff?

- should add a debug feature like https://blog.rust-lang.org/2019/01/17/Rust-1.32.0.html
  - and make it so it only gets compiled in when you run it in a "debug" mode so the
    code can be let in, with optional tags etc.

- When optimizer inlines a function that has an arg used as a function for DynCall
  but called statically, it still introduces this unused variable.
  - probably want to remove unused args generally.

- should have slaballoc use indices so allocation granularity can always be smaller?
  especially when using 32-bit emulation.

- should make if/while conditions detect non-nil variables as always true conditions and
  optimize accordingly.

- contribute Lobster syntax highlighting to:
  https://github.com/github/linguist/blob/master/CONTRIBUTING.md#fixing-syntax-highlighting

- make metadata more readable in generated C/C++.
- could make simplifications to bytecode format now that tocpp/disasm is only consumer.

- add support for pure functions.
  introduce functions with e.g. "fun" instead of "def" to indicate they are pure (much like
  currently "let" and "var").
  A pure function is not allowed to mutate anything external to the function. It still is
  allowed to have a var and update it, or even a var with a locally allocated data structure
  and update that, just not update any free vars, or data pointer to by free vars and args.
  This analysis runs for every function, such that functions declared with def that are
  actually pure will get a warning that they could be declared with fun.

- remaining improvements we can do related to return values.
  - allow dynamic dispatch overloads to be specialized on reqret etc.
    - dynamic dispatch overloads should have better return value type checking, probably by
      coercing them at the end?
  - codegen: remove special purpose use of rettypes, replace by regular types.
  - codegen: remove dropping in codegen to just follow typechecker?
    - though codegen dropping is recursive, e.g. it drops 1+2, though not sure how useful that is
  - we have 2 types in nodes, do we actually need them?
    - see below how we didn't decide to remove coercion nodes.

- tagged arguments in Lobster for function calls.

- Improve threads.
  - Consider spawning the workers from their own source code?
    - benefit: cleaner separation, simpler code, simpler to forbid stdlib access.
    - that would not work from a bytecode-only situation, or would require compiling
      a second .pak for workers.
      Or, simply a second bytecode in a .pak
    - would not guarantee same types sent across so needs more complex serialization.
      - flexbuffers?
  - Would be good to reduce globals, and/or not make builtins that rely on globals available
    to worker threads.
  - Allow any data to be passed between threads.
  - Use it in some compute heavy samples like smallpt.

- binary string ops:
  - memcpy, memmove
  - write_string
  - ops for doing things with unsigned values stored inside signed ones?

- We should ideally enforce non-escaping lambdas at compile time.
  Currently, "benign" things happen at runtime if you try, since the set of all vars is
  always available, and if you return to a function from the lambda that doesn't exist,
  you simply terminate.
  But would be good to exclude this. Problem is that there are legit use of lambdas
  stored in data structures that are not escaping but hard to prove that they are.

- enable dynamic function value call on any exp, see ParseDeref.

- gltf loader?
  - could use this: https://github.com/jkuhlmann/cgltf
  - or instead create a schema for FlatBuffers so it can be read directly.

- nice samples to port:
  https://github.com/ssloy/tinyraytracer

- strong typedefs.
  Will basically add a tag to any base type.
  If a functionally specifically requests the tag, the tags must match.
  In any context a type is allowed to lose its tags (coerced to base).
  This way, we can have the few functions that actually want string to contain
  utf-8 take this typedef. Or strings can specify they contain a FlatBuffer
  or some other specific binary layout.
  For scalars and vectors, the tricky thing is that you want some weird
  defaults for operators:
  for +, strong + strong = strong, anything else results in base type.
  for *, strong * base = strong, since you're often scaling a unit.
  It should be possible to override these defaults, disable operators, or
  specify relations with other types, but the default for a type should work
  intuitively for most types (especially spatial quantities, as Lobster is
  game oriented). This overriding is something for later.
  Besides the type system dealing correctly with tags, we now need general
  casts (allow a typedef as function name). We may also need to make string
  constants result in a utf-8 typedef by default.

- A minimalistic error catching feature.
  I'm not a fan of exceptions anymore (though they can be emulated in Lobster in user code),
  and I generally don't think runtime errors should be catchable.
  But functions that bounds-check indices stored in user-generated data such as for reading
  file formats and serialized data break this model, in that you do NOT want user code to
  error/bounds check every single read, yet program terminating upon corrupt data is also
  not that great.
  For that purpose it is maybe useful to have a minimalistic error catching mechanism.
  Since we already have code that rolls back the stack upon an error (and generates an error
  string), we can simply use that code to check if the current function is a function that
  would like to return the error string and continue executing as normal.
  This function must have a return value of type string? (such that nil can mean no error),
  or string if so desired,
  and must somehow be marked as error-catching. If the unroller finds such a function it stops
  unrolling and returns the current error string. The function can also return other strings
  under normal execution.
  We can even provide a function to generate such runtime errors, so that people can abuse it
  as a simple form of (string only) exception handling if they wish.
  Of course can complicate this feature to not make it string only, but I don't think that is
  necessary. If you want to create complex exception hierarchies you are probably using the
  wrong language.
  Might be worth doing at least the initial version of strong typedefs first since that will
  allow a runtime_error string type. Though that tag would have to survive into the vm data.
  Though, there is really no reason for this error string to be forced to be the return type,
  if instead you store it in the VM instance, then the function itself can be any nillable,
  where nil now signals failure rather than success which is more natural.
  Also, rather than a function annotation it can currently just be a builtin function
  that marks the current function as error catching, since it can simply register the
  current function stack frame function id as such, though that may make future optimisations
  to omit it harder.

- namespaces improvements:
  - also implement them for global variables.
  - extend non-namespaced "methods" to out of line declarations.
  - Private functions and data types do not appear to be deleted at the end of an include
    currently, see EndOfInclude.
    - what if they are overloads?

- The way WASM deals with signed/unsigned is correct, everything signed, with special ops
  (not types) for doing unsigned semantics on signed bits.
  We should adopt this for Lobster by providing the exact same unsigned ops as special functions
  (e.g. udiv, ucmp or ulessthan etc.)

- Should really move away from a Makefile for Wasm, there's been plenty of cases where bugs
  appeared because certain files weren't recompiled.
- Wasm: With asyncify, still instruments functions it shouldn't, mainly in the SDL.
  Try with --pass-arg=asyncify-verbose
  https://github.com/WebAssembly/binaryen/commit/f632c1fd62a588c83237d2d7018745c3f20eff66

- Make includes explicitly depend on eachother.

- We have a check in IdentRef::TypeCheck to avoid escaping lambdas, but this only works
  for static ones, not for calls over a function type.

- Should consider an SSA based IR to sit in-between the AST and bytecode gen.
  - This can do more precise dataflow based type and lifetime checking.
  - Also a better basis for more hard-core optimizations.
  - Would have to move the typechecker to it to get the most out of it.
    To make that not a crazy effort, can think of a hybrid model where any sub-parts
    of basic blocks that do not interact with SSA form can still be AST trees?
    So basically the control flow constructs get SSA-ified, and every basic block is
    an AST, with SSA references baked into it.
    This way it can be done incrementally, one construct at a time.
    Then later can decide to flatten this AST into a list of instructions if desired.

- would nil as sentinel have advantages?
  - would need to specialize lots of opcodes and functions that call .True(), so probably not.

- besides exception.lobster, another nice error-handling strategy would be to use nillable to
  signal errors. returning nil is a bit primitive, but in lobster it has the nice property that
  it forces the caller to check for nil, making errors not-ignorable. It also means we can
  use standard language tools like if/and/assert rather than special purpose error handling.
  - would need some way to store additional error information external to the value.
    in the simplest case a global last_error:string
  - doesn't work on functions that want to return scalars. should really make boxed values
    possible outside of any, such that you can actually have int? types.
  - the best language addition for this which is generally useful would be to have
    a := return if not f()
    where f returns a nillable, a is non-nillable, an the surrounding function again returns a
    nillable.
    as an easy way to perculate errors.
    in e.g. Rust this is a macro that looks like: let a = try!(f())
    Probably a more verbose syntax that contains "return" is better, since returning from a
    function is major control-flow that you don't want hidden in a macro. Also nice that in an
    editor you can highlight all the returns.
    Can also have "return if" that does the reverse: return a non-nillable if true, otherwise
    continue execution. This is like doing "return f() or .." except here it is easier to
    make the ".." contain multiple statements.
    This is nice, because "return if not" is for NOT dealing with errors locally, whereas
    "return if" is for dealing with errors locally (coming up with an alternative return value
    upon failure).
    "return if" also usefully turns a value non-nil without needing a temp var, normally you'd need:
    temp := f(); if temp: return temp
    Also, both of them promote more linear code.
    - note there is some code in the impl that assumes "return" has no temps on the stack,
      which isn't the case for: 1 + 2 + 3 + (return if not ..)
    - for completeness, can even have "a := return b if not c", which is still better than
      "a := c; if not a: return b"
  - so far there isn't a lot of error handling going on anywhere in lobster code.. I guess
    because games don't do a lot of error handling beyond loading files. And GL errors are
    wrapped in native code.
    Could be good to write something that does a lot of error handling like a parser, then
    again the above constructs sound generally useful
    - parsers are better of using "return from" as form of exception handling.

- try again having --tocpp output basic blocks as switch case rather than function pointers.
  - try with clang to see if it optimizes that case better
  - try and explicitly jump to the next function where known statically rather than using the trampoline?

- always fun to rewrite the implementation in itself..
  - this would actually not be super hard.. the frontend and the VM can easily be in different
    languages.
  - can even implement any part of the compiler in lobster itself, by just calling it from C++.
    For example, the parser. it would just need a built-in to construct nodes etc.
    Either interpreted or to-cpp would work.
    Actually, don't even need to call it from C++, it can simply be an independent Lobster
    program generating a pakfile.
  - Maybe more productively, as noted elsewhere, could write the graphical debugger UI in
    Lobster itself.

- make extensions (and --tocpp code) into DLLs rather than statically linked?
  - check performance consequences for --tocpp

- Can turn exceptions back on in emscripten once this fix lands:
  https://github.com/emscripten-core/emscripten/issues/7399

- This doesn't typecheck correctly:
  if !lhs:
      lhs = ...
  // lhs here required to be non-nil.

- This doesn't parse:
  somestruct { def ():
    multi-line-anonymous-function-body
  }

- def adder(x): return def(y): x + y
  print(adder(1)(20)) // test.lobster(2): error: identifier expected, found: 20
  It thinks is its parsing a lambda.. can this be a better error?

- This parses the map without the lambda:     assert 1 == map(2) i: 3

- a file with only an include statement in it gives: error: linefeed expected, found: end of file

- Swift's weak pointer feature has some merit.
  It's not a real weak pointer in the sense that it still holds an object alive, more like a
  "2nd class" refc.
  So an object would have 2 refc. If you have the classical cycle, of root -> A, A -> B, and
  B -> A, A would have refc=2 which is the problem. But here, A would have 1 strong, and 1 weak,
  allowing the deallocation to continue. At first strong drops to 0, but weak does not, so it
  is kept alive. Then once the weak also drops to zero it gets deallocated.
  - Note: apparently Swift uses a global hash map to clear backpointers, which is terrible.
  - Also see: Nim is using the annotation .cursor for weak refs.
    https://www.youtube.com/watch?v=aUJcYTnPWCg
  - Vale has good ideas: https://vale.dev/blog/raii-next-steps

- font rendering:
  - it is possible when only very few chars are cached, that they are placed higher in the bitmap
    if all their bounding boxes are small.
  - outline rendering needs to do a better job that pixels stay in the bounding box.

- Can't call o.f() where f is anonymous function value, need to first assign to temp var.

- also allow explicit a.x, a.y = f() multi assign, this should be easy now that AssignList
  takes lvalues because of with defs.

- A "warning: expression has no effect" would be nice, for when you mistype `a += 1` as `a + 1`

- if we make assert a language feature rather than a builtin, we can make it understand
  equality operators directly, and create specialized asserts that have better errors, i.e.
  any "assert A == B" can actually output the values of A and B.
  or "assert var" is pretty common, which can output the name of the var, etc.

- need some way to typecheck append([type_A], [type_B])
  neither either:
  - some kind of cast (may be universally useful), or compile-time C# "as" (never nil)
  - a way to annotate append as returning the super-type of both inputs.
  - some generic type system smarts that when arg N is supposed to match arg 1,
    if it fails, it first tries to both make them into superclasses before erroring.
  How many functions are there likely to be like this, beyond append?

- typeof gives static type, needs to be dynamic when used with ref objects.

- type errors should skip large amounts of globals for __top_level_expression()

- In this kind of code, without the type annotation, the list specializes it to subclass
  and fails the remove_obj:
  def supermethod(.., list:[supertype])
      list.remove_obj(this)  // Type error without the annotation.
  Not sure how to solve that, as auto-specializing "this" based on other args may be weird.

- in a struct foo { a:float = 1.0 } allow the :float to be left out
  problem is, we already have default values on fields that are intended to be generic, in
  e.g. astar.lobster

- bring indent based syntax for struct defs also to struct use, vectors, enums..

- support loading from pak files in --cpp mode.

- compile-time lobster execution would be super simple: simply allow a string that contains
  lobster code, spin up a VM to eval it, and insert its result back in the code.
  print eval "1 + 2" would actuall compile: print 3
  But not quite as nice as a real macro facility, since now you have a large block of string
  in your code, for more complex cases. And no easy way to do instances/parameter.
  And errors that refer to code you can't see.
  Can however also take exps as input like a real macro system, though having a ton of functions
  to access and create AST nodes not as easy as string processing?
  Can make AST access pretty generic, though there are lots of little features that may need
  special accessors, and the code producing this will look less readable.
  Can do an inbetween where all args to the macro are strings, though they may have types for the
  caller that restrict the kinds of inputs.
  So, hygienic inputs but not necessarily outputs :P

  macro DEFINE(name:ident, t:type, init:exp):
      return "let {name}:{t} = {init}"
  DEFINE(a, int, 1)
  print a

  the types ident/type/exp would be strings inside the macro body.
  the "macro" definition would not actually parse the body of that macro, since we need it as
  text to invoke a new VM with. It would prefix it with `let name = "a"` etc to execute it.
  Then the resulting text needs to be inserted in the parent similar to an import statement.
  Hmm, but the caller of a macro can't just call ParseExp() etc, since we don't these to create
  AST nodes that we then have to convert back to string, worse, they can't have an effect on
  the current parser state like requiring a variable to exist.
  Better to wait until we have the first use case for it?

- if your forget ":" after "else", it is going to try and declare a following identifier as a
  function parameter, see FIXME in ParseTrailingFunctionValues

- Should consider to allow on-the fly data structures as well.
  Writing new_type { field1: val, field2: val } would add such specialization to new_type even
  if it doesn't exist yet.
  Should change data structure specializations such that the collection of things under new_type
  doesn't need to share a generic parent, and in fact may have different fields etc.
  Specialization then takes care of checking the different variants in use.

- Should we consider default-const?
  Bit odd for a language without type annotations, but if the syntax for mutation was light,
  it be a very nice feature to have, especially since the vast majority of args don't need it.
  Only needed on struct/vector.
  Syntax could be a single char token attached to any ident decl?
  def f(a, @b): b[0] = a
  @a := g()
  where token could be: @ # ~ ! $ & * = ` in that order
  A keyword like "mut" is a bit too obnoxious?
  token could also follow the ident.
  Could allow a command-line arg or annotation in file to indicate that code doesn't care to be
  const-correct :)

- for easier integration of the language part into other projects:
  - rename stdafx.h
    - make public headers explicitly depend on it.
    - try to reduce the scope of it.

- We should consider splitting the type checker in particular, but potentially also parts of
  parser/opt/codegen into more passes.
  This is a more complicated change that will not be easy.
  In particular, type-checking of struct decls has ordering issues that creep into the language,
  forcing users to declare things in a particular order that is not obvious.
  This is hard though, because:
  - types of fields may depend on initializers which depend on globals declared before it which
    depend on other classes..
  - other types (super classes, generics, fields) may be quite circular.

- Add an optional mouse smoothing feature?

- Have a simpler/better C++ binding interface.
  - for starters, should allow current binding system to be loaded from a DLL/so such that
    extensions don't have to be compiled into the main binary.
    - needs some versioning.
    - also, if those extensions need the basic engine functionality, need to first refactor the
      engine functionality to sit in an interface pointer or something.
  - Worth discovering if the current macro glue can be improved, maybe with automatically
    deduced arguments from a C function or C++ method.
  - Could do something similar to CryScript: declare external functions in lobster, generate
    glue code automatically.
    - causes a code-gen step whenever adding new functions.
    - You declare in one place, and the second use is a copy, but the two have to be kept in sync.
      - enforcing the two are in sync is done by the C++ compiler, which is nice.
  - One fun idea is to support Python DLLs/so's.
    There's a TON of C/C++ libraries out there for Python.
    - Such a DLL returns a DLL module structure, which we could traverse to find out what
      functions are in there.
      - They are of course untyped, showing up in Lobster as any functions?
      https://docs.python.org/2/extending/extending.html
      (see also e.g. dynload_win.c in CPython)
    - Not obvious how this would work in terms of memory management, as Lobster would have to
      allocate potentially complicated Python values from Lobster values that then get accessed
      by the DLL (which contains a subset of the Python runtime?)
    - Most interesting libraries like Numpy come with a ton of wrapper code in Python, which means
      just exposing the DLL functions would end up with a very different API, or you'd have to port
      all that Python code.
    Frankly while it would be cool, there's too much of a mismatch for this to make sense?

- function-level profiling of actual time spent.
  The current line level profiler is useful, but counting VM ops is imprecise, and doing it once
  per instruction is wasteful.
  If its inside the function-calling mechanism behind an if (profiling) that is branch predicted,
  it can be always in there (maybe #ifdeffed out for --tocpp).
  Can also count all builtins automatically.
  To do exclusive counts, can simply have a global that counts how much time children have
  accumulated so far, to substract from a parent. This works recursively because it is postfix!

- Should consider type-safe type aliases, where converting from the base type is explicit, mixing
  with the base type degrades the type, and mixing aliases is a type error. Would be a feature
  entirely implemented in the type checker only, as an additional tag on type values.

- would be nice to have on the fly pairs/tuples.

- in def(x::type) if x is subtype: should children of the subtype be available inside the if?

- add options to either show more extensive stacktrace dump to either stdout or file.

- Typechecker can actually blow the 1MB Windows stack space on complex programs.
  Set to 16MB for the moment.
  Each function nesting can easily take 10 calls, and since even simple if-then's
  do this, it quickly adds up in number of calls.
  Need to create an explicit stack for recursive calls.
  - Apparently the amount of guard values inserted in Debug seems random and can be quite large, it
    appears to be using 5-10x as much stack as in release mode, so stack defaults should reflect
    that.
    - checking stack usage with /RTC off (on language project) is more meaningful -> rebuild.
      Reduced stack usage by.. 2.5x?
    - Even after that, the amount of stack space in the function prologue being allocated by
      lea rsp / rbp setup is way bigger than the amount of locals?
  - Even release mode stack frames are huge, similar to debug with /RTC off.
    /GS off seems to make a huge difference in release, unlike debug, 4x in some cases.
  - Maybe add this for Linux/OSX:
    https://stackoverflow.com/questions/2275550/change-stack-size-for-a-c-application-in-linux-during-compilation-with-gnu-com

- inlining has kind of broken the variable stack trace. not only are certain functions gone,
  it can now show multiple variables of the same name and variables that are not really in scope
  anymore.

- Should probably allow named functions as function values too.
  - See could_be_function in parser.
  - Need to make sure this works with overloading, templates, etc..
  - There are various places in the code where we assume "anonymous" is very different from named.

- the codesize optimization where we introduce a function type for gui_button or whatever
  should really be possible to be done automatically, as long as it doesn't touch functions
  like map for which performance may be important. could have an easy way to annotate a
  function argument saying: make all compatible function signatures go thru the same
  specialization. Or maybe more sane, do that by default, and have an annotation to inline
  for the few functions where that matters.

- Transition to a more modern graphics API + platform layer? Options:
  - Stay with OpenGL+SDL
    + Easiest, pretty solid, simple, doesn't require pulling in huge libs.
    - Advanced features only work on Win/Linux.
  - https://github.com/floooh/sokol
    + By far the smallest / simplest option.
    + Gets us DX11/Metal level features.
    + Also replaces SDL.
    + Well integrated with Wasm/Web.
    - Requires external shader compile to target all of these :(
  - https://github.com/bkaradzic/bgfx
    - Big and bulky compared to sokol, brings in stuff we may not need.
    + Brings Vulkan level functionality.
    - Probably also needs some shader compiler.
  - WebGPU native.
    + Could be a well-specced, solid API that's simpler and more portable
      than Vulkan.
    + Easy integration with Wasm/Web.
    - Native implementation is bulky (Dawn) or depend on Rust (gfx-rs).
    - Spec not settled, shader situation is a mess.
  - Vulkan, haha.

- Replace audio layer with https://github.com/mackron/miniaudio ?
  - Seems to be more featureful than the SDL stuff, built-in mp3 etc.

- function call optimization and simplication.
  - make a micro-benchmark to compare against other languages.
  - inlining
    - named functions
    - how does removing single-use functions relate to function values stored in variables
      (and in variables of function types), and as arguments to builtins like hash/gl.translate.
  - remove static function arguments
    - or maybe better to generically remove vars that aren't used.
  - C++ backend: detect when not needing to return to trampoline?
    - need to know when "broken" by a function call.
    - though given that the switch/jump method is slower, maybe not a priority.
  - change var access to be relative to top of stack
  - cleanup of id/sid/arg..

- Make loadtexturecached into something using a generic map. But to declare it, need to be
  able to specify generic vectors in struct decls.

- consider baking Z up into functions.
  - clean up 3dhelpers?

- have a reference counted resource handle instead of ints.

- Could provide a compilation mode where this is compiled in: https://github.com/bombomby/brofiler
  Would be able to show a nice nested view of the cost of all lobster functions and builtins.

- use RangeCheck in more places.

- this crashes on += in codegen:
  team_colors := [ color_grey, color_red, color_blue, color_green, color_yellow, color_cyan, color_pink, color_light_red, color_light_green,
                   color_light_blue, color_light_yellow, color_light_cyan, color_light_pink, color_dark_red, color_dark_green, color_dark_blue, color_olive ]
  team_colors += map(48) i: team_colors[i % 16]

- weird error:
  struct controller { startpos:xyz_i = xyz_0i, endpos:xyz_i = xyz_0i, startinpal:int = false, endinpal:int = false, valid = false }
  controllers := map(2): controller {}
  error: no specialization of controller matches these types: xyz_i xyz_i int int int

- also, == should not do pointer equality on value types! have to use equal for now

- excellent candidate for a 3D physics engine to integrate: https://github.com/RandyGaul/qu3e
  Or: https://github.com/jrouwe/JoltPhysics see https://twitter.com/erwincoumans/status/1496513233146068992
  Or of course Bullet!

- for any error related to a builtin function, can also print argument names and helptext.

- syntax: "if c: a, b = exp" doesn't compile if the multi-assign is on the same line.

- typechecker
  - would be nice to have a way to indicate a generic argument that must be a vector, possibly
    as just []. See for example match.lobster that works on generic vectors.
  - x[i] does not do flow analysis.. not as trivial to add if i is an exp or could change.
  - if !a: a = ..
    // here a is still nillable.

  - flow analysis should also know about if !a: return; a // not nil here

  - if you do [int] + [float] you get "error: "+" (left argument) requires type: [any], got: [int]"

  - should constants be excluded from freevars to reduce clutter?

  - must be able to derive type from default in struct def

  - can we avoid .length giving errors with variables initialized to [] before a push etc?

  - improve type checking doc.

  - move generic double check from parser to type checker init

  - why do we need .xy ? shouldn't xyz convert to xy when needed silently thru inheritance?

  - can we make the astar_node specialization less ugly?

  - should fields be allowed to have types of generic structs? can be a bit confusing that the containing
    struct becomes generic because of it but doesn't look generic.

  - add more cases to typecheck if-then optimisation.

  - Annotate builtin ops that truely want a vector, not a struct substitute.

  - returning an [int] from vector < ops is both incorrect and wasteful

  - what gets collected in "freevars" for each function is overly broad for HOFs, see CheckFreeVariable.
    This is benign, but would be nice to clean up.

  - see if we want to do something about the explosive cloning caused by gui.lobster
    we may want to use an explicit function type for situations like this, since we do want most HOFs to inline.

  - if you typecheck a function with a supertype, then a subtype is able to reuse it. But if the return value
    is now also this supertype you have a contravariance problem. Either must not reuse the function (but only
    if the return type is affected?) or subtitute the subtype somehow..
    This is affected by the order of source code, so can give weird errors.

  - flow sensitive checking does not work if part is skipped because a function has already been typechecked and
    is reused (same args and freevars), so should apply same demotes.
    Can this ever happen? can we guarantee it doesn't? Or for now just force a specialization if it has demotes?
    x := "" | nil
    function f(): x = nil
    if(x):  // promoted
        f() // demoted
    if(x):  // promoted
        f() // nothing happens, f() has already been typechecked

  - value structs are still compared by reference.. by value would be better, which also means we can choose
    to copy them and store them wherever.
    See e.g. gui.lobster/element()

  - check: a dynscope redef must have same type as its parent
  - improve GenScope now that we have pre-parsed sf.dynscoperedefs

  - make function calls with trailing nilable arguments default, as long as they're not ambiguous with sibling
    functions.

  - a := nil; a = 1 // allows creating nilable scalars, which we don't want, though its benign

  - We compile time optimize if-thens for constants, but this does not include cases that would
    need constant propagation, like astar_2dgrid isocta.
    Should reduce total cloning quite even further.
    issue: how can you do this with arguments that may be constant for the first call, but you
    don't know how many calls there will be yet?
    -> maybe we should analyze the if-then to be constant, but don't actually cull the code, leave
       that to a seperate optimisation pass. The branch will simply not be typechecked for this
       specialization.
       Though that would mean we'd need to make this boolean part of the type signature,
       because otherwise a second call with a different boolean value would reuse it,
       and run into un-type checked code.
       We already specialize on nilable/non-nillable, and specializing on booleans sounds attractive,
       though we don't generally want to specialize on ints or other values, unless we made a special
       annotation for it.
       We can stick an int value in the V_INT union for Type, and ignore it pretty much everywhere
       except for specialization.
       This does mean a lot more type allocations (one for every constant in the code, could hash).
       The type should propagate automatically.
       We'd have to be very careful about propagation, i.e. typechecking 1+a getting the type of 1.
       - any such combinations come almost always from Union(), so the amount of cases should be controllable.
         Also: variable binding.
         x.push(1) could make x a vector of 1's, and subsequent push of 2 doesn't fix that.'
       - also if someone writes 1+1, we'd have to eval that in the type checker.. we'd end up duplicating
         a bunch of functionality of the optimizer.. though that code is shared in ConstVal().
         In fact, if we expand that function, the optimizer can use it generically to optimize code,
         and doesn't have to repeat that code.
         Even better, the type checker can use it for generic typing, and reduce its code as well.
         Only downside is that its a bit more cpu intensive, since there is a double switch for each
         node, and worse, additional recursion which is only useful if it returns true.'
       Also must check there are no direct comparisons against type_int.
       We'd need a special value to mean not const (e.g. 0x80000000) which in this case is fine
       instead of an extra boolean.
       Then we check these values when we check for specializations.

  - we don't do flow-analysis for v[i] or v[i].f etc, is that possible?

  - need a better solution than replace() for assigning to read-only structs

  - from the previous astar_2dgrid:
        distancef := function(v): ...
        if(isocta):
            distancef = function(v): ...
        the assignment won't work. Now you could make it an if-then returning the function value,
        which will get you a dynamic call, and no specialization.
        frankly, its worth rewriting this such that it can be specialized, especially since thats
        free if isocta is contant

  - this language does very similar type inference, and has some interesting additional ideas:
    http://crystal-lang.org/2014/04/27/type-inference-rules.html
    - true union types rather than any.
      Not sure how useful this, since at runtime you still need the same type field, and knowing it can have
      a smaller set of possible types is not THAT useful, as it will still be slow.
      The biggest improvement would be in type errors, so now it can say instead of "expected int, got any"
      it will say "expected int, got int|string".
      Problem is that they are expensive to represent, as in its most generic form, they are a vector<Type>.
      We could cheat however, and make all the basic types (int/float/string) into INT_ANY etc variants, that
      have the other type as a subtype. Basically, the same as ANY for the purpose of most typechecking code,
      but carries more information for errors.
      It would also be useful for if(x is int):, because if x is ANY_INT, then the else branch x can have the
      parameter type (or if its ANY_FLOAT or ANY_STRING, and the parameter is INT).
      We can't do this with parametric types. Though in theory ANY_VECTOR could first have its own parameter followed
      by the second type, this won't work if either of those contain a struct/function/var type.
      Of course you could have VECTOR_ANY only work with int/float/string sub types, and the second type could be
      anything, which would be at least a small step forward, i.e. instead of "expected [int], got any", it
      can now say "expected [int] got [int]|[mytype]", but then if we have more complex types, it would have to
      resort to "[any]|[mytype]" (which is confusing) when really you want to say "[mytype1]|[mytype2]".
      In that case just "any" might be better?
      Of course, we could switch to a type representation where the index and the types fit in the same kind of
      fields, in which case we can represent any unions as long as there is space:
      STRUCT_ANY, idx1, STRUCT_ANY, idx2, STRUCT, idx3
      would be a union between 3 struct types.
      Simpler, we could bloat up the current union to allow 2 sub types, then any could simply be a union of
      those, and it would even work recursively.
    - It also does more accurate flow based tracking of variable types, e.g. an assignment inside
      an if() in Lobster only destroys the type promotion, here it changes the type promotion.
      That be easy to add, by storing the type promoted to rather than just the fact that something was promoted.

- In :: blocks, can now call other methods without "this", but:
  - also should be possible without () (see capped_storage() in cityclicker.lobster)
  - also should be possible to leave out variable name before ::

- There's a possibility gl.set_mesh_texture will hold on to texture ids that get deleted.
  Would be nice to avoid this, but don't want Mesh to have to hold on to an LResource, or
  have to implement a second level of refcounting.

- remove last cases of RenderArraySlow
  - cache for text VBOs, and cache for arbitrary polygons, cleared if not used in a frame.

- This doesn't parse well (see std.lobster):
  for xs: acc1, acc2 = fun(acc1, acc2, _)

- improve indentation parsing, e.g. here it needs else to be at the same level as the var:
  v := if ..:
           ...
       else:
           ...

- allow random number generator to be selected

- add a way to limit fps, regardless of what system is capable of.. particles in physics in particular doesn't function
  correctly at high fps.

- A path towards value types, less reference counting, and less runtime type information.
  - We can start with builtin functions, and mark arguments as not requiring reference counts
    increased, and thus all dec-refs can be removed from their code.
  - We add a set of pushvar and related instructions that does not inc-ref.
  - initially just in codegen, and extra arg to codegen for an exp says that the code should
    not inc-ref (using these new instructions, or if too complicated, just add a dec-ref).
    - actually adding a dec-ref is complicated, if an arg is a new string, or some exp that
      returns a new string, the dec-ref needs to be after the call if the builtin isn't going to
      dec-ref.
  - now in the type checker we can do an analysis whether any variable will ever have inc/dec-ref
    applied to it, this then transitively works through functions.
  - initially this just reduces reference counting overhead, but this paves the way for
    efficient value types.
  - We can now split reference types (initially just structs, later maybe vectors) in two types,
    where the value based one points to the memory after the reference count in a struct type.
    Value types are stored in-line, are passed by pointer, and assigned (and returned) by copy.
    Maybe the ref count can live before the pointer to keep the two compatible?
    To be precise, we got 3 types:
    - Value types, never ref-counted.
    - Struct non-ref-count, passed as if value type, only if can be analyzed to not need ref-counts.
    - Struct ref-counted, can be passed to non-ref-count context.
    Since there is already a value/struct distinction, we can start by making values stored
    in-line, before we even do analysis for structs.
    All of this is completely transparent for the user, as there will be no new errors generated,
    unlike say Rust. They will get the benefit from in-line types and low ref-count overhead
    pretty much for free.
  - Related to this is the removal of the type field currently in structs (and vectors), such
    that values can become completely naked and maximally efficient.
    In the type system, types are almost always already known statically, so we should be
    able to remove the type value, and have the compiler insert it as separate value (a hidden
    arg when needed for builtin calls that want an any type).
    This is of course best done once most uses of this type field have already been factored
    out.
    Or better yet, change the encoding of "any" such that it is a generic object that just
    bundles a type and a generic value, and is like a built-in value type. This can be used
    for "any" and dynamic dispatch.

- make more args const

- Add #line to C++ output: http://yosefk.com/blog/c-as-an-intermediate-language.html

- Implement these examples in gui.lobster: https://github.com/eugenkiss/7guis/wiki

- in VM stack traces, linenumbers for blocks if/then etc often refer to 1 beyond the last line of their body,
  which is unhelpful. Should see which instruction they refer to, and which node generates that lineinfo.

- should redo gui.lobster to take all args in virtual float coords, not some in float font relative coords and some
  in pixels.

- should consider allowing local functions to be declared with "public", which would expose them to closures called
  from within their parent function. This would allow the whole definition of gui.lobster to be inside gui_start.
  It would create kind of an inverted object, so all calls could lose the gui_ prefix since they're not global anymore.
  Would probably work together well with frame state.

- the "ERROR: XAudio2: XAudio2Create() failed at initialization" is apparently happening on all sorts of cheap laptops,
  including Win7 & 8. SDL folk don't seem to want to fix, it, maybe I should

- supposedly on OS X error window OK button is not clickable?

- add more to http://rosettacode.org/wiki/Category:Lobster
  once there's no more syntax changes.
  https://www.google.com/search?as_q=&as_epq=You+are+encouraged+to+solve+this+task+according+to+the+task+description%2C+using+any+language+you+may+know.&as_oq=&as_eq=&as_nlo=&as_nhi=&lr=&cr=&as_qdr=all&as_sitesearch=http%3A%2F%2Frosettacode.org%2F&as_occt=any&safe=images&as_filetype=&as_rights=#as_qdr=all&q=site:http:%2F%2Frosettacode.org%2F+%22You+are+encouraged+to+solve+this+task+according+to+the+task+description%2C+using+any+language+you+may+know.%22

- docs:
  - not clear
    - value ... people used to doing v.x +=
    - else: if:
    - that you can make your own control structs in your own code: examples focus a bit too much on for/if
    - the single graphics matrix stack
    - more on debugging
  - tutorials
    - absolute basics for those that don't know programming yet
  - shader system
  - performance - do benchmarking
  - gui system
  - better language cheat sheet ?
  - web page:
    - link to reference and docs more for things that are not explained (e.g. ::)
    - more images to cool samples written in lobster, to entice what the language can do.
    first maybe add more/better examples

- examples:
  - more/better examples..
  - also make more basic games people can start from

- builtin functionality
  - stb
    - try out stb truetype
    - ogg loading -> stb (streaming vs loading?)
  - more sound functions: stopping a sound early, volume, getting notification when a sound stops playing,
    software-based audio mixing, some way to loop sounds.
  - sphere-to-frustum intersection for easy culling
  - TCP-IP? enet?
  - JSON
  - launching processes and other shell stuff

- disadvantage to Lobster being based on immediate mode rendering is that that is quite taxing on the speed of the
  language, since you need so much code to just decide what to render each frame
  directions:
  - add display lists or something so it is easy to cache rendering calls, and the code generating them doesn't need
    to be called every frame
    ideal for level backgrounds etc.
    though complicates things a tiny bit, as now you have to decide manually when to re-render certain display lists
  - have an additional retained mode system (probably combined with physics) that would be doubly useful
    in some cases
  - work on optimizing the language a bit more

- when running with no args (trying to load a .lbc), current dir should be aux dir when running from commandline

- make it more straight forward to use as an embeddable scripting language
  - add functionality to call individual functions inside a script

- if we ever want to run directly on Metal or whatever, this looks useful:
  - https://tellusim.com/shader-pipeline/
  - MoltenGL commercial / not oss, and only GLES2, whereas the tellusim one could
    translate GL4.x shaders, though sadly not at runtime..
  - This is oss, supports ES3, and presumably allows runtime shader translation:
    https://github.com/kakashidinho/metalangle

- think about how to support a debugger
  - would be great if it could be written in Lobster itself:
    have to figure out how to have a frozen VM, and have debugger code running
    and how they can share graphics state
    maybe we can allow multiple windows to start? can make objects that hold window+context+all other graphics state,
    and allow each VM to open 1, or even multiple per vm
    if that approach doesn't work, can make a debugger that is a webserver inside the lobster exe, as that's nice and
    cross platform.
    But better to try multiple windows first, that be good for threading and other features anyway.
  - Actually a web-server based debugging interface might be good, use e.g. this:
    http://runtimelegend.com/tech/webserver/
  - might be fun to see how hard it is to write an integration for http://lighttable.com/
    which could be used as a debugger and maybe for live-coding.
  - Could integrate with VSCode instead.
    - Sadly the Language Server system is overly complicated, requiring JSON RPC over HTTP to
      communicate.
      - but the communication channel can still be stdio!
      https://www.reddit.com/r/Compilers/comments/p2wql5/do_someone_need_a_starting_point_to_build_a/
    - Should maybe start with just the debugger, as it is simpler (can communicate over stdio)
      https://microsoft.github.io/debug-adapter-protocol/

- function f(): x := 1; x + x
  gives error on x... should disallow

- make win32 version not a console app
  - need to save lobster text output always to a file, so when it crashes user can send me that
  - can always type/cat it to show output
  - ideally lobster has a callback for program output & errors
  - trace output also to a file

- BitmapFont::height is often 1 or 2 bigger than the original fontheight, which creates problems if code use the
  fontheight for rendering instead of gl.text_size()
  either improve the math such that they are guaranteed equal, or document that fontheight should never be used for
  rendering bounding boxes etc

- Icon style matching on vectors or strings, whereby the current vector and position are stored globally, so you can
  easily write match('a') | match('b') etc. and find() and other type of searches/matches that string function and
  regexps generally do. And easy string extraction functions.
  Could use a HOF to be the stack context of these functions ... can even write it in Lobster itself (with private DS
  variables) if speed isn't an issue.

- transforms:
    - cannot use matrix functionality for own matmuls etc -> need loadmatrix etc
    - localmousepos and hit are nonsensical when perspective is on

- should all gl calls check minimized themselves for programmers that don't check gl.visible() (gl rendering when
  minimized crashes on IOS)

- for mgtest or other games with long load time, have a way to not have an uninitialized window while loading
  - could add a system for threading long operations like this...
  - or an easy way to render a first frame?

- a program that reformats lobster code to conform to the style-guide better.
  Not a trivial program since it can't reuse the existing Lobster lex/parser, since that throws too much information
  away
  Will need to be a "conservative" program, yet it must understand enough of program structure (with indents and
  multi-line exps) to reformat correctly.
  Must also respect aligned spacing in places.

- calling mg_scale_vec(1, f) where f = nil doesn't work (see codegen NCM_CONT_EXIT).. probably doesn't happen a lot, but
  needs fixing

- other IQM features
  - make bone count dependent on max uniforms, and make it an error to load a model over that.. or find out what minimum
    uniform count is on relevant OpenGL ES 2 devices
  - can very easily count max weights and choose a shader with less mats
    maybe add some conditional feature to the shader parser to make this easier
  - currently scaling is multiplied into the mats if its in the file. Either make scaling an error, or use this to
    transfrom the normal:
    mat3 madjtrans = mat3(cross(m[1].xyz, m[2].xyz), cross(m[2].xyz, m[0].xyz), cross(m[0].xyz, m[1].xyz));
    http://www.arcsynthesis.org/gltut/Illumination/Tut09%20Normal%20Transformation.html
  - maybe use dual quats?

- improve gui.lobster
  - pop up menus
  - multiline text editing system

- should lobster transition to a callback model per frame? that's how mobile devices like to interact with your program,
  and SDL does some pretty nasty stuff to emulate the pc way of doing things on there.. can we bypass that?
  Hmm that doesn't require a new programming model.. we can just have gl.frame() suspend the VM so we can return from
  our frame callback

- optimisations:
  - could add an optimizer with constant folding, constant propagation and inlining, esp inlining of hofs very important
    - ideally, need to additionally have a way to do while/if/for without function values, while is terrible atm
  - think of ways to simplify function calling
    could keep a simple function reference count, so we can only do the expensive backupping for recursive functions
    NOTE: recursive calls are not the only situation that requires backups. A simple map(): map(): .. does not look
    recursive, but has the same implications.

- per function real cpu profiling would not be too expensive
  just a single qpc per call -> no, 2, needs stack
    no, can do it stackless if we change the "definedfunction" saving to keeping a current one and saving the previous,
    that way on each function entry/exit we know who to attribute the current elapsed time to
  gotta be able to display hierarchically blocks under named functions
  alternatively, could just do a ++ every instruction to count instructions... not quite as accurate an indication of
  performance, and harder to display compactly since you'd have to display it next to the lines in source

- compressed loading/saving using my entropy encoder

- didn't solve no mouse up msg when leaving window

- see if we can get page aligned memory with VirtualAlloc / mmap for slaballoc

- making SDL manditory:
  + it's already mandatory on Android/iOS
  + error handling
  + can make features that rely on graphics, like a graphical console/print, graphical debugging, could kill the DOS
    console
  + if graphics are mandatory, frame based state makes more sense.. its a bit odd if such a thing is a gl. feature, but
    hey why not
  - no more console-only programs possible.. reduces its usefulness as a general purpose programming language
  - don't want to have it initializing graphics before compilation... probably can just do it before VM init
  - killing DOS console means giving up notepad++ integration
  - right now, lobster could be used as a plug-in scripting language by simply not binding all the graphics stuff
  at first we can just init SDL at the start of the program, then graphics optionally during execution. this gives us a
  lot of the combined benefits.. the only thing we lose is not being able to be a plug-in language
  alternatively, we can make on-demand init of SDL a bit more modular, so that it can be called upon when threading is
  needed etc.

  Ideally the dependency graph is:
  base <- engine    <- bindings <- main
       ^- compiler  <-/
  So someone can use just the compiler without the engine.
  A simplified version would just be (this is the current situation):
  compiler <- engine <- main
  In VS, the language project compiles without needing SDL or anything beyond stdlib, we
  should keep it that way
  The usefulness of being able to use the engine without the compiler is low.
  Engines are a dime a dozen, and this one is not particularly featureful, and quite specific to
  its bindings. If you really ever wanted to do a C++ project with this engine and without
  using Lobster, the fact that the compiler is compiled in doesn't hurt anyone.

- some kind of profiler:
  - measure instruction inside named function
  - number of calls of builtin functions

- a := a // where a is an arg is allowed

- dispatcher:
  - rewrite the dispatcher to be in tree form
  - can add subtypes that don't have their own case? how about single variant functions?
  - make type+idx into shorts, so they can be checked with a single compare?

- bytecode version of compile_run()

- typing:
  - also support withtype for "method calls"
  - ::= op (first find a convincing use for it)
  - could make it a warning or error if X.field is used where X has been withtyped

- get rid of client side data VB rendering by putting rect/line/circle etc in a static vbo, then transform with mvp or
  uniform

- fix localmousepos to be a position in front of the camera in 3d mode? and in the middle in no cursor mode?

- hiding the console unless there's output for graphical applications
  note this screws up notepad++ capturing output

- multiple errors

- make comparators non-associative?

- pattern matching by failing a function into the next

- make bytecode, not intcode.

- FIXMEs


Locally Declared Class Members NOTES
====================================
  * It is super common for some API (e.g. imgui) to leave the across frame state storage to the caller,
    which results in all these helper variables in the containing class that have no purpose other than
    in one function.
  * What if those vars can actually be declared in the function?
    Kinda like C "static", but for class scopes.
    Kinda like Lobster's removed frame state feature, but again, for classes.
  * The variable would be visible only in that scope, but stored in the class.
    It would need an initializer, since class construction must always initialize it.
    So in the simplest case it would be:
    member sel = -1
    sel = im_listbbox("foo", sel)
  * Would this only work for "methods", or any first arg with a withtype ::, or any first arg at all?
    It's a fun feature for a free-standing function with a generic arg to be able to add state to
    multiple classes in modular fashion:
    def stateful<T>(t::T, ..):
        member track_thing = 0
        // track_thing is now a member of any T this gets called on.
    Likely requiring :: is a good idea, since it makes the decl/use look identical to inline methods,
    makes it clear param 1 is special, and it would be odd to declare the var as `a` and then use it as `t.a`.
    If needed, allow it without :: also but then it has to be declared as `t.a`.
    If needed, could allow :: to be used on args that are not the first, but this is not in line with
    the special status of the first param elsewhere.
  * Since these members are not accessible outside the scope, they are by definition for transient
    uses of data (since you can't even serialize them manually), so should be excluded also in
    any generic serialization/parsing/printing functionality.
  * Philosophically, this makes a lot of sense: frame based state had the issue that you needed
    conditions and loops to drive the lifetime of the state, which was often tied to particular
    objects being visited or not. Here you do the same, but much more directly.
    If an imgui is editing particular object state, then its gui state is tied to that one object,
    not to the frame.
  * You can think of this feature more generally: a function that has state it wants to survive
    over multiple calls. It turns out that the class context as indicated by first argument is a
    good default, but maybe there are others, there might be such functions when I call them in
    a loop I want to have that state be a local variable in the parent function instead of
    in a class? I guess that is not as valueable because you could already have a function that
    returns the current state and then tracking it in the parent was very local.
    The class case is both more prevalent (since an object indicates lifetimes we care about)
    and it also makes a bigger improvement (since member variables are in scope of a LOT of code).
  * A related idea I had that maybe can be implemented alongside this:
    Scoped member variables that are lifetime bound to the function they're in.
    This is kind of the opposite of the above, since it is not meant to survive one call,
    but is similar that they're bot not visible outside the scope.
    def garbage_collect(os:[Object]):
        member visited = false in Object
        // complex recursive algo goes here that marks objects as visited.
        return os.filter(): _.visited
    You can of course do these things with an extra array, but now the array, index, and object
    need to be passed to other functions where in this case just object would suffice.
    Of course you permanently take space in the object, but that could be mitigated by the fact
    that 2 such variables could overlap in storage?
    Gets maybe a bit complicated as a feature?
    Though, just having a syntax to indicate that the hidden field is to be added to a specific
    type instead of the type of the first arg would be cheap to add and enable these kinds of
    use cases.
    In the end, besides having decls more local, the other idea is that its cheaper/simpler to
    piggyback "associated" storage in parent/key objects.
  * How would this be implemented? In the non-generic inline method case it be easy syntactic sugar,
    since it could just be lifted to a field decl for the surrounding class, but in the generic
    example above it can only be added to T once the caller is being compiled, and by then T
    may already have classes that inherit from it, etc, which would have to be taken into account.
    (Or error if its not a leaf class?)
    Since T is fully specialized by the time the member gets added, it can add it for each specialization
    separately, and since its only used in that specialization there's no need for it to be at the same
    offset as other classes etc, except for sub-class insertion.
    You'd need to check if it already exists (and must have the same type) since two specializations
    of a function that add a member may be called.
    If it was already added in a subclass and now added to the superclass you'd need to move the field
    for all subclasses for this to work!
    If you wanted to simplify you could start with leaf classes since most recipients of these
    members are "environment" style classes that typically are leafs.
    Alternatively, allow it only in inline methods at parse time, so fields are automatically added
    to subclasses.
  * Since we must allow it to be declared in multiple places, it makes sense for the programmer to
    also do that on purpose, and have 2 functions that work on the same state. Of course at some point
    it becomes better to make an actual class but there can be uses for this.
    It is almost like a mixin, and you could imagine it having special syntax to allow groups of
    functions:
    mixin:  // Doesn't need a name, hah!
        a = 1
        def geta(): ..
        def seta(): ..
    However:
    - 90% of uses are likely single function so this syntactic overhead is unwelcome.
    - disallows these functions to be declared in disjoint places.
    - would disallow declaring the var deeper in the method next to where it is actually used.
    - kinda messy that you now need to check both methods for the type to add to, and..
      specialize them both at the same time?? Or add a generic param to the mixin decl somehow?
      This clearly would not work well.
  * what if you want two instances of the state?
    In the case that you're wrapping an `new = f(..., old)` style function, you can do that
    yourself thru naming.
    In the case that you are calling a generic function like stateful<T> above, you can't.
    I guess these are for fairly specialized uses? What's an example of a use where you'd want 2?
  * the most minimalistic version of this functionality would be to at least allow members to
    be declared mixed with functions, so it could be made obvious they belong to one method.
    This would miss out on scoping though, and refusing external access.
    Or, you could a syntax similar to the mixin above, but only allowed inline in classes.
    There, it would almost be a no-op in that usual class parsing would apply, except now
    it can use the mixin as a scope demarkation, not allowing access outside of those functions.
    You could even do that implicitly saying a middle-declared var is only available to the one
    method following it but that is kinda hacky.
    Though, not sure why you'd want any of these minimalistic versions if an inline-method only
    version is so simple.


LIFETIME NOTES:
===============
- reference counting is a good default, but it is a source of much more inefficiency than I had
  guessed. Should consider what it would take to add a friendly ownership model.
  Examples:
  - My past languages SHEEP and CryScript
    - SHEEP has full value semantics, which to the user looks like copies, with lots of built-in
      operators and functions that make use of linearity to do in-place updates.
      it has: newvec, oldelem = oldvec[i <- newelem] as a way to update a data structure, which
      ensures nothing is copied or thrown away. If newelem is nil, it becomes a cheap way to
      take an expensive element out of a vector without copying.
      It has limited borrowing, with built-in functions annotated as "promise I won't keep a
      reference"
    - CryScript produced a tree of regions at runtime, where regions are attached to certain
      object types. regions would be entered and excited automatically with methods on that type.
      You can explicitly designate a parent region to e.g. allocate things to be returned from
      a boundary method. Trying to create a reference from outside a region to inside was
      disallowed at runtime.
  - ParaSail
    the semantics of all data structures are by value, sees an object with a nillable field
    as "extending" a flat value when set. does copy/move/swap, but does not have borrow.
    Has an interesting loop syntax that "hides" borrowing to get around the lack of borrowing.
    https://en.wikipedia.org/wiki/ParaSail_(programming_language)
    https://drive.google.com/file/d/0B6Vq5QaY4U7ubm5qVkFpMEtmN2s/view
  - Rust. needs waaay to many type annotations and relatively complex analysis to work.
    definitely needs to be simpler than this.
    - Example of the horror to avoid:
      https://rust-leipzig.github.io/architecture/2016/12/20/idiomatic-trees-in-rust/
      (his library does NOT even implement a delete method!)
    - https://stackoverflow.com/questions/34747464/implement-graph-like-datastructure-in-rust
      Basically, you either use an arena (and leak!) or you use a hashmap (and have potentially
      dangling references).
    - So rust is really only nice if you can keep to really simple data structures?
  - Nim: seems to have a nice middle ground inspired by ParaSail.
    https://nim-lang.org/araq/destructors.html
    https://github.com/nim-lang/Nim/wiki/Destructors
    Actually this latest version appears inspired by Gel below:
    https://nim-lang.org/araq/ownedrefs.html
    The idea of leaning on typed allocators to allow unlikely dangling (and thus not
    having to do refc in release mode for example) is pretty damn smart.
    You could make this model even simpler, by just ignoring the refc entirely, even in debug,
    so you just have owned vars that blindly deallocate, any amount of non-owned aliasing,
    and typed allocators, giving you speed, safety and simplicity at the cost of the occasional
    unwanted sharing of dangling objects. Nice for a "small language".
  - Gel: https://pdfs.semanticscholar.org/d0f2/d28962d2a50d1914f0af8243d3f382fe077c.pdf
    Very pragmatic and much simpler than Rust, but still needs too many ownership annotations
    for things that should be obvious.
    Interesting that it still does refc at runtime, presumably to make the type system more
    lenient, but it doesn't explain how.
    It has a nice way of reducing reference counts that could also be applied to a traditional
    (non ownership) reference count language.
  - Swift 5 is going to get on this bandwagon:
    https://github.com/apple/swift/blob/master/docs/OwnershipManifesto.md
    While it already has COW for some types which in theory should make ownership easier, it
    is apparently a complex enough language that it would require runtime read/write status
    tracking for every var that could give dynamic errors to guarantee integrity, which seems
    terrible.
    Luckily Lobster doesn't have most issues in this doc, thanks to its callgraph based type
    checking and specialization, and lack of runtime generics, escaping closures etc.
  - This paper eliminates inner borrowed variables from reference counting:
    http://liu.diva-portal.org/smash/get/diva2:20899/FULLTEXT01.pdf
  - Dyon: https://github.com/PistonDevelopers/dyon/issues/173
    This requires the programmer to get lifetimes right using annotations, ordering or clone
  ops.
  We'd want to keep Lobsters light syntax, so any system that requires type annotations
  frequently can't be used. 99% of code should "just work", even if it occasionally makes
  copies you don't expect.
  Unlike Rust, we don't have to care about a single mutable borrow, since we don't have any
  interior pointers nor do we intend to do shared memory concurrency.
  In terms of ownership, we have two modes: move (transfer ownership) vs borrow (can be mutable
  or not).
  - an expression/constructor always moves.
  - an assigment wants to move.
  - a variable can be initialized either by a move (most expressions) or a borrow (an expression
    that reads from a data structure or variable).
    - if it was a borrow, all its uses must be borrows as well. The parent variable must be
      be marked as having been borrowed from, which disallows deletion etc., and must outlive
      the borrow.
    - if it was a move, it owns the data. all uses must be borrows, except the last one may
      be a move.
      - a special case can be made to allow moves into data structures that are not the last
        use, e.g. a := newobject; x.y = a; use(a), since the code after the can be transformed into
        a` := x.y; use(a`)
        Can do the same with push(), i.e. code afterwards becomes a borrow on the last element
        of a vector, which locks the vector as "borrowed from"
  - function arguments should default to borrow (mutable or not), but can be marked as move
    in special cases. Move is used for:
    - putting inside a data structure, such as push()
    - arguments that are lobster "value" types when the result is also a value, this way
      the memory can be used in-place.
  - function return values usually move. they can borrow if the exp is field/var reference,
    if we can correlate the parent to var in the caller?
  So now, for any value being passed, if source and dest modes are NOT equal, we get:
  - if src wants to move, and dest wants to borrow, then src has to delete after borrow ends.
  - if src wants to borrow, and dest wants to move:
    - if it is non-mutable, a copy is made.
    - if it is mutable, error. This is because a copy would change semantics.
      (see variables above for how this can be overcome in some situations)
  In both cases the "fix" is done by the src (caller), which increases the chances the fix
  can be avoided (as opposed to the callee always allocating/deallocating).
  In theory we could use lobster specialization to let the caller determine if they want
  move/borrow for each param, and specialize if they differ per call. That way each code
  pattern is efficient. Sadly that also means that a mutable borrow after move will error
  at the move, rather than at the borrow.
  So maybe better to resolve these after the function has type checked.
  Implementation wise, we have the advantage that for a while we can keep refc, so we can
  check the inserted deletions against the refc to see if they're correct.
  The good news is that this system can be entirely done without annotations of any kind,
  and is efficient (only values are copied, which currently are always small).
  The big downsides are that you can't form DAGs or graphs anymore.
  Would adding non-mutable vectors have any advantages? those could always be consumed by a move.
  Another way to look at it is this simple starting point: for each function block, end by
  deallocating eveything locals hold, but never deallocate arguments. Then most of the lifetime
  analysis is about when to change those defaults for particular variables.
  --
  Its pretty easy to still have refcounting as well, simply by having a level of indirection
  (a cell object referring to a refc object) this way the cost of refc is only paid by these
  objects, and inc/dec can happen at creation/destruction of the cell object (so is cheaper
  than the refcounting we have now, since you don't pay the cost on any parameter passing).
  Interestingly, you could actually use this for all values: an ownership analysis, which all
  it does is compute lifetimes for all refs, and inserts an incref where the above algo would
  do a copy/error.
  Or more generally, you could allow the programmer to specify what he wants to happen on a
  multi-ref: a copy (for non mutable / small / stack alloc), an error (for efficient mutables),
  or an incref (for flexible mutables).
  We can achieve this with a 3rd type beyond value / struct.. maybe "owned" or "linear"?
  Or make struct linear, and have a "reference" or "shared" type.
  The other cool thing in terms of seeing things this way is that you can first implement
  the reference count for all types, see that it works, and then only after introduce the other
  two.
  --
  Good to read the Gel paper again because it defines type checking rules in terms of expressions
  having ownership types rather than in terms of transitions, which seems easier to deal with
  in the type checker. Still, different transitions have different properties, so core
  type checking functions will need a context parameter.
  --
  Sound borrowing.
  Borrowing a single variable is easy by locking that variable for the lifetime of the borrow.
  Borrowing a field means locking the object and the field, but still allow writing to other fields.
  Borrowing a vector index op would meaning locking the vector and that element, but that means
  proving that any mutations on elements during this borrow are guaranteed on other indices.
  This is possible in some limited cases, but generally very hard to prove.
  It is made even harder by all the vector ops, like remove() etc.
  It may well be that the easiest strategy is borrowing only for variables and fields, and
  making indexing instead not borrow, but keep.
  Besides the indexing op, also for loops would need to do this, since they imply indexing,
  though maybe better have these still borrow, but block mutation on ALL elements?
  In addition, objects and vectors that are not a single variable (in a field or index op)
  need to also not borrow, with the exception of chained field accesses probably.


TYPECHECKER NOTES:
==================
- free variable pre-specialization implementation:
  in essence, to be fully correct, a function value must be specialized to its free variables when the
  the function value is *created*, and to its args when it is *called*.
  We must thus specialize at creation time.
  This first requires we use SubFunctions as type-ids because otherwise this specialization will
  get lost thru multiple calls. This should not affect us using Function ids for return-from etc, as these
  can still be retrieved.
  Then, how to specialize:
  at creation time:
  if first sf is not freevarchecked, just use that one and mark it as such.
  otherwise, check all specializations (typechecked or not, but only with flag freevarchecked) for a match in freevars.
  otherwise, if none of the current specializations fit the current free vars, force a clone, and point to that.
  Make sure we set the types of the freevars to their current values (move from TypeCheckCall).
  this forces that type-system-wise, no two functions with different free vars have the same id.
  Might make sense that if there are already multiple subfunctions that have matching freevars we always pick the
  last one (the first one added), such that these kinds of function values always have the same type, though it
  may not matter.
  This should not affect function type definitions, as this is an explicit type check
  at call time:
  We must now not terminate at the first untypechecked function.
  If the current sf is not type-checked, we can simply go ahead and use it.
  Otherwise, checking all alternatives includes freevars, so will select or clone the right one.


CURRENT SOLUTION FROM TRADEOFS:
===============================
- We removed co-routines. They're a "sexy" feature everyone always seems
  excited about, but in practice in games they are not all that useful.
  I end up never using them, and when I do, it is for uses that can easily be replaced by
  a class with an update function.
  Having cross-frame state in locals is really not as nice as in member vars.
  It could be cool in complex multi-stage animations.. but even for those it is questionable,
  as code that interrupts/changes these animations then becomes more complex.
  Fundamentally, state that survives a frame needs to be carefully managed regardless.
  Co-routines have also been an endless source of complexity in the VM, and don't fit
  with Lobster's new focus on efficiency.

- decided against:
  - change V_MULTIPLE into types always being a vector:
    - while it simplifies some cases that currently have to check against V_MULTIPLE, it
      complicates a ton of code that wants to pass or check a single type.
      Current solution actually rather nice. Also gives nice errors on unexpected use of
      V_MULTIPLE rather than needing to check that everywhere.
  - use std::variant for nodes in Lobster? or other things like types?
    - std::visit will have horrible performance in debug for that many nodes, also hard to
      debug.
    - nodes can be inline in their parents, total much less allocations.

- namespaces:
  Syntax-wise we've been using _ for hardcoded namespaces so far for both builtins (gl.text)
  and libraries (gui_text). I kinda prefer that syntax to . or ::, it makes the namespace
  obvious part of the name and feels more lightweight.
  Though . will be more familiar to people, and makes leaving it out more natural.
  If we change to . then builtins should also use it.
  The advantage of _ is flexibility, for example string_to_unicode could be considered to be part
  of a string namespace, but it is kinda not since length doesn't use it, and for
  unicode_to_string the namespace is on the other end. Also string.to_unicode doesn' look as
  good. And since string is not a "class with methods", i.e. length is a free-standing function,
  we wouldn't want to namespace it since string.length is too verbose.
  _ allows you to fluently mix namespacing and names, as long as things are "unique enough"
  Ok, so assuming we keep using _, how do you create a namespace?
  We could simply have a "namespace gui" declaration, and all top level names get automatically
  prefixed when used outside the namespace.
  Alternatively we could have namespacing be decided by the user, by having
  include "gui.lobster" as gui. If you leave out the as-part, you instead get it dumped in the
  current namespace.
  Hmm.. defaulting to namespaced as declared is probably better, "as" could be optional renaming.

- you can hit multiple overlapping hit boxes with gl.hit(). problem is, you render back to front, but want to hit test front to back...
    - if you simply clear that a hit happened this frame when its tested, you get that order wrong
    - if you added z-layers to rendering such that you could do inverse order
      - if you did it immediate mode, blending wouldn't work correctly, so it would have to be understood that if you did did multiple layers for hit testing, you can't hit on an alpha element
      - could store all render calls and sort (or just reverse) them after, but this is a lot of storing of stuff
        we would store color/blend/transform/shader/texture/linemode for each, which is not that much of an overhead since we set these things on every render op anyway
        (except blend/texture/linemode which can be set when changed),
        so its purely the cost of allocating/storing, and complicating the code a little
    - could track an event handling closure and handle it it at the end of the frame. certainly the simplest, if not totally elegant
      (extra call to handle delayed closure, and delayed closure can't access free variables)
    - you could compare the current hit rect against the last rect that was hit last frame, and if they are the same, this is the one to fire
      problem is, this doesn't work on touch screens, where you lose the first touch down event this way
      -> unless you delayed all touch down events by one frame, to give one hover frame to register (this is the current solution)
    regardless of the solution above, you also need an additional way to cancel hits that happen inside a toolbar or statusbar that may not have hittests everywhere
    -> that can already be done by a gl.hit that doesn't react to it's return value

- for things like GUI callbacks, lobsters non-escaping free var function values kinda suck. options:
  - just call em in place, can only really work in a non-immediate mode gui since otherwise the callback can change the gui layout
    - use caller_id() to make the gui aware of inserts/deletes so this is now safe <- curent solution
      - instead of caller_id could have created a vector of args to the gui function as identity. slightly more correct for calls in a loop, but more work.
    - alternatively since all troubles are caused by element insertion/deletion, have special functionality for turning things on/off, i.e. gui_if() instead of if()
  - call em afterwards: problematic because variables not available
  - call em afterwards & force it to take an arg. not elegant, but atleast the arg will remind people to pass values this way
  - implement full closures for escaping situations
    - don't really want another programming language feature just for this
    - to create closure, would need syntax at the call site which is clumsy if it gets forgotten, and some new data structure to hold vars
    - would have to back up old vars, load vars from closure, call function, and put old vars back
    - would probably have a special way to invoke closures so that we don't have to clutter normal function calling, and its easy to give errors if a non-closure is passed in
      still, there has to be some indication on the stack that we're returning from a closure
      though I suppose it can work like coroutines, where upon returning from the function it hits a special instruction that does the cleanup
    - maybe also have a static type for it so no syntax is needed at the call site
    - so in summary the implementation effort is a simplified version of coroutines.

OBSOLETE
========
- How to implement (free) variables more efficiently:
    - implement free vars differently from regular ones, options:
      1. simply keep free vars in the vars array, and regular on stack.
         - closest to how it works now
         - 2 kinds of vars, 2 kinds of prologue/epilogue / 2 kinds of instructions
         - kinda natural though, freevars become like "globals" in C.
      2. turn free vars into extra args (and extra return values)
         - maybe the most efficient, since inlining will have removed all intense use of free vars
         - only left with 1 kind of var
         - can do it incrementally, first with the current var system.
         - must detect when free vars are accessed mutably
         - function return must be modified to first write N rets back into vars
         - bad because of large number of "globals" ?
           - tested this, buts some of my program have multiple functions with like 50+ free vars
             due to this, and most not even constant. gets worse with all the nesting.
             So ideally free vars need to not have cost while not accessed.
      3. address free vars over one or more "frame pointer" hops
         - hardest to get right, and most different from what we have now, and all in one go.
         - slower
         - also inefficient with "globals"
      4. make instructions to access from the bottom or top of the stack
         - bottom most useful with globals, which are 99% of uses of free vars
         - doesn't work for a freevar in the middle of 2 recursions.
         - potentially a function needing a free var can be reused, but with an extra function
           in between.
         - essentially similar to (1) since also needs extra instructions, but a little simpler
           since stack-frame creation can be uniform, but with the downside that guaranteeing a
           fixed offset is harder.
           So essentially (1) is similar but by reserving fixed space for all possible free vars
           on the bottom of the stack first, and then not allocating them in the actual stack frame.

- 32-bit compressed pointers in 64-bit
  - exampler: https://wiki.openjdk.java.net/display/HotSpot/CompressedOops
  - If all objects are 8-byte aligned, and if a << 3 is ok, can address 32GB.
    - Not only that, this only has to store program objects (and maybe code), not things like
      textures, geometry, etc which are stored in GPU memory. So for a graphically rich game
      where typically 90% of memory usage is such assets, this 32-bit model can grow until
      320 GB of memory usage for a game is not sufficient. It thus defers the need for 64-bit
      so significantly that it becomes practical to target the language to be 32-bit only for
      the foreseeable future, with all the efficiency and simplicity that brings.
  - if the base address is a multiple of 4GB, then compressing can be a simple truncate
    instead of add/substract, and no conditional to compress a nullptr.
  - needs a conditional to decompress nullptr, unless base address can be 0. That's a huge win,
    which may be possible be we can assume a 32GB range.
    - though we have seperate accessors for pointers that can be null, so if the majority is not of
      that type, it may be ok.
    - still, not having a base address may be a win by itself.
    - can simply iterate with mmap to find a large block as low in memory as possible.
      that should generally not fail?
      - On Windows, simply turning of ASLR (/HIGHENTROPYVA:NO) allows compressed pointers to
        work without additional work.
  - can avoid a conditional to decompress nullptr if we manage to make all tests for null to
    be (== baseaddr) instead.
    That may be tricky since we use the fact that int/float/ptr all have 0 bits as false
    representation to be able to check them without knowing the type with True()
  - A base of 0 with <<3 is very efficient, which on VS win64 was 7% faster than native 64-bit!
    Using clang it was about the same speed.
  - on platforms where we cannot interact with the system to constrain our address space, can
    create a really dumb allocator that simply re-allocs a buffer containing all memory when
    needed. This is bad because:
    - Such big reallocs may cause a pause (speed of memmove is typically only a few GB/sec),
      though typically only happen once or twice during a game run, hopefully during loading.
      If using realloc(), you may get lucky and no memmove is needed :)
    - You temporarily are using 3x as much memory as allocated (current mem + new 2x size block).
      Should not be an issue on 64-bit.
    - May cause issues with fragmentation causing such big allocs to fail, though since this
      technique is only used on 64-bit systems that should be unlikely.
    So in total this is acceptable, and then on a per platform basis it can be replaced by
    a more efficient strategy.
  - will NOT work in the default trampoline compiled mode, since we store function pointers in
    values there. Have to use the switch mode instead.
  - More good tips in the comments here:
    https://stackoverflow.com/questions/50429365/what-is-the-most-reliable-portable-way-to-allocate-memory-at-low-addresses-on
  - it would be nice to make a distinction where we use compressed pointers only when stored in
    structs/vectors (so those can be 32-bit always, or still 32-bit even when we allow different
    sized scalars in these data types).
    The stack is a really small amount of memory, so keeping that 64-bit should have no effect
    on cache usage, yet it is the highest frequency access, so naked pointers are a small
    speedup, allow for 64-bit datatypes, easier to debug etc.
    - the big question with this model is float conversion speed.
      http://quick-bench.com/T_FhqmN-7RG_oIEsf4Ur-rCFww8
      Shows that having everything in float, or everything in doubles, or stored in floats
      and accumulate into doubles are all equally fast, but what is 3x slower (both gcc and clang)
      is stored in doubles and accumulate into floats, as that requires an explicit cvtsd2s
      instruction.
      So that should be acceptable as that is the least likely case, happens only when writing
      results back into fields/vectors.
      - vector ops can still be all-float
  - Could remove the need for a base address by making everything a relative offset
    That way, your only concern is to keep all memory within an arbitrary 4GB (or 32GB) range,
    which should be easier, and doesn't require OS support.
    The one issue is that it still needs a special case for null.
    - you can make that actually 0, assuming pointers never point at themselves, such that
      a null-check can happen before unpacking, and hopefully code that knows something is not
      null can avoid this check entirely.
    - the alternative would be an offset towards the base address, but that is way more
      expensive to check.
    NOTE: relative offsets will not work unless we disable copy constructor on Value, and track
    down each and every memcpy or whatever of values
  - older notes:
    Could somehow make all the pointers stored in there into 32bit offsets in 64bit mode (and still raw
     pointers in 32bit).
     This would generally be good, since using less memory in 64bit could be quite a speedup.
     Problem is, there's no super elegant way of doing this.
     - Ideal would be if the OS would allow use to make all allocations come from a 32bit range, but there's
       no support for this.
       Instead, can use mmap() with MAP_NORESERVE on Linux/OSX/iOS/Android to just get a large chunk of memory,
       and then use that incrementally. Means we must have our own large block allocator however.
       On Windows VirtualAlloc can do the same.
     - could track all allocations in the allocator, but means also tracking "large" allocs individually,
       finding these in the table will slow things down, and means code can't run with the base allocator anymore.
     - simpler, could require the allocator to re-alloc when it needs to grow. If we can guarantee all pointers
       in it and towards it are offsets, this can work.
       Problem is that these large reallocs can fail, i.e. might not work well for memory contrained systems such
       as iOS whenever it goes full 64bit.
       Also means we can't use the base allocator anymore.
     - Could track all allocations in an IntResourceManagerCompact.. that's a fair bit of extra memory usage
       though for small objects.
     The problem with this approach is that there is no way to do operate on 64bit datatypes in any way this way.
     Another problem: the ip's stored in Value are native function pointers in C++ mode and would need to
     be indirected.

- Improve 64bit builds.
  We currently can build for 32 and 64, and in the latter we use int64_t & double, which gives
  bonus precision, but uses exactly twice as much memory, since all Lobster memory is made out
  of these values.
  Suprisingly, for our unit-test path-finding benchmark, 64-bit mode this way is actually
  23% faster (VM mode, only 16% in C++ compilation mode), despite using more memory, that is
  apparently how much the VM code benefits from extra regs etc.
  Now this benchmark probably touches so little memory it all fits in cache, but for most
  Lobster programs that don't touch a ton of data, 64-bit mode is thus not a problem, in fact,
  it is a speedup.
  We can still improve this situation in two ways:
  1) Could allow types of different sizes at least in vectors and structs where they take the most space, and
     leave them uniform on the stack. Start with vectors as that's easiest and most impactful.
     Have a way to specify bit-width for both scalar types (only allowed to be smaller or equal to machine type).
     default would always be machine size everywhere.
     If we're lazy and don't want to deal with different sizes in structs, can at least allow size to specified
     for struct as a whole if all elements are scalar. This not only simplifies things by keeping
     indexing the as-is, but it allows faster vector ops by only having to check the bit-width
     once rather than every element.
     The advantage of the stack staying 64-bit is that you can then actually make use of 64-bit
     precision when you want to, something which is not the case in 2)
     How to implement:
     - Vectors can be created with an annotation to their desired bit-width, which becomes part of
       its type.
       - We have to ensure these get checked thru-out, so maybe safer to have special VECTOR_INT
         types etc.
     - Similarly, structs can be declared with a particular bit-width. They can be specialized into
       other bit-widths.
       - sub-typing check, cannot allow these specializations to be compatible with eachother.
     - In both cases, the bitwitdth is actually stored in the header of the object.
     - For direct loads and stores, we use specialized VM instructions, causing no overhead.
     - For generic code (builtins) that wants to read vector/struct elements, we provide a generic
       accessor function that dynamically loads the right size.
       - Sadly, there's no "read an int of n bytes" instruction in C++.
         Edit: there kinda is, see use of __movsb in flexbuffers.h
         on x86 you could read an int64 from the memory location, then use shifts to clear the unused bits
         that preserves the sign (>> is an ASR):
         value = ((value << 32) >> 32)
         to convert 32 to 64.
         though note: http://blog.regehr.org/archives/738
         On arm, unaligned access is allowed for single scalars on most v6 and all v7 architectures, so maybe its
         a non-problem.
         It will be slower, but since it only occurs for vectors that try to save memory, its probably ok.
         Can we avoid the unnecessary shifts when reading default size value (shifts will be 0) ?
         Still need a conditional for floats since the shift trick doesn't work there. Worse, now we generically need
         a conditional to check for floats.
         Maybe allow bit sizes only for ints?
         If its only for ints, how useful is it to have it at all? We already have a [byte], namely string, so it
         would only be for 16/32 bit int vectors.
       - frankly, a generic accessor function is a bad idea. Pretty much all builtins take a statically typed
         2/3/4 int/float structs, so we should be able to change the accessors to directly access these.
         Only problem is requiring them to be one size, e.g. 32bit. Even though we can maybe make the
         default specializations 32bit, people might expect to be able to specialize xyz for 64bit and
         still have all these functions work.
         We could overload all these functions..
       - Also would be helpful to change some vector builtins (like append) to lobster code, such that specialization
       can still allow them to work on these vectors.
     - For compact structs, currently will be wasteful that in RefObj refc & ti can be 64-bits.
     1b) Alternatively, if the above is not all that crazy useful, implement my "typed buffers" approach
         and store the buffers inside strings.. doesn't need a new type, and allows all sorts of fun optimized
         data structures.
         Also cool for serialization.
         And helps more generally combat the heavy nature of non-inline objects.
         Then again, would be even better if structs could be separated from vectors more so we can add these
         features (variable data sizes, inline structs, trailing vectors) to regular structs.
     Hmm, trailing vectors means reallocation, so not good to have in regular structs.
         Actually, no need to separate them, can just disallow them to be passed to generic vector functions.
         Only valid for structs that look like a vector.

NOTES:
======
- mrgreenfur has the lobster.io domain we could use as a new homepage..
- http://rigaux.org/language-study/syntax-across-languages.html

SPEED TESTS
===========
secs measured in release win32 on speedtest.lobster, all other figures in debug.

The first 9 numbers were run on a 2600K, but have numbers by 1.77x/1.43x adjusted for it
being slower than the 8700K being used after that, such that all numbers are comparable.
From (1) on they are on an actual 8700K, and also bumped iterations 10x.
At (2) bumped iterations 20% because a bug in GOAP was fixed that made it faster.
At (3) completely reworked benchmarks to add a lot more variety, but balanced to
still take the same total time for comparison.
At (4) Here we switch from the 8700K to an AMD 3950x. Though in benchmarks it is faster single-core
than the 8700K, it is way slower at running Lobster, possibly branch mispredictions are a heavier
penalty? All score above (4) have been updated to reflect this speed difference, to make
future scores comparable with past ones.

VM: last_dyn_typed    : secs 72.2
VM: last_switch       : secs 64.6
VM: over fun ptr      : secs 50.0
C++: first comp       : secs 40.0
VM: first inline      : secs 46.8
C++: first inline     : secs 35.5
VM: inlined for       : secs 37.1
C++: inlined for      : secs 23.6
--
VM: inlined for       : secs 36.9, 1.77x vs 2600K (1)
C++: inlined for      : secs 23.6, 1.43x vs 2600K
VM64: inlined for     : secs 30.1, 1.23x vs 32bit
C++64: inlined for    : secs 20.3, 1.16x vs 32bit
VM: vec/struct        : secs 33.4
VM64: vec/struct      : secs 26.7
VM64: may 2018        : secs 27.2
VM64: compr_ptr       : secs 25.6, 1.07x vs native pointers
VM64-MSVC: oct 2018   : secs 27.6
VM64-LLVM: oct 2018   : secs 26.3, 1.05x MSVC (without -flto, which doesn't work)
VM64-LLVM: compr_ptr  : secs 26.7, 0.98x vs native pointers, unlike MSVC!
VM64-LLVM: dec 2018   : secs 25.9, return value related refactorings.
VM64-LLVM: lifetime1  : secs 26.3, lifetime off (4649 alloc, 105402 decr)
VM64-LLVM: lifetime1  : secs 23.5, first ever lifetime, few optimisations (4649 alloc, 7175 decr)
VM64-LLVM: lifetime2  : secs 24.0, first lifetime commit, slightly conservative (4649 alloc, 18858 decr)
VM64-LLVM: lifetime2  : secs 23.8 (2)
VM64-LLVM: lifetime2  : secs 23.9, strings pooled (3945 alloc, 13126 decr)
VM64-LLVM: lifetime2  : secs 23.9 (3) (332258 alloc, 636280 decr)
C++64-LLVM: lifetime3 : secs 18.5 (with LLVM, LTCG doesn't appear to work under VS)
C++64-MSVC: lifetime3 : secs 16.3 (LTCG on)
VM64-MSVC: lvalinl    : secs 23.3 Inlined the LvalOp function, one less switch()
C++64-MSVC: lvalinl   : secs 15.1 Inlined the LvalOp function, one less switch()
VM64-MSVC: inlinestr  : secs 21.3 inline structs v1
C++64-MSVC: inlinestr : secs 15.3 inline structs v1
C++64-MSVC: immediates: secs 14.6 direct immediates in native code VM calls
C++64-MSVC: dd        : secs 14.0
VM64-MSVC:            : secs 20.2 (newer VS, better release settings??)
VM64-MSVC:            : secs 18.3 (newer VS, "for/if/while" compiled slightly differently)
VM64-MSVC:            : secs 19.1 (newer VS?)
C++64-MSVC:           : secs 11.8 (newer VS?)
--
VM64-MSVC:            : secs 19.1, 1.265x slower than 8700K (4)
C++64-MSVC:           : secs 11.8, 1.18x slower than 8700K
VM64-MSVC:            : secs 19.1, stack pointer instead of index, no change
C++64-MSVC:           : secs  8.9, stack pointer instead of index, 32% faster!
VM64-MSVC:            : secs 17.8, named inlining.
C++64-MSVC:           : secs  7.6, named inlining.
C++64-MSVC:           : secs  7.4, __force_inline on VM functions.
VM64-MSVC:            : secs 16.4, pass stack pointer around explicitly.
C++64-MSVC:           : secs  6.2, pass stack pointer around explicitly.
C++64-MSVC:           : secs  5.7, put sp in a non-ref var.
C++64-MSVC:           : secs  5.4, vars inline in VM object.
C++64-MSVC:           : secs  5.0, specialized array indexing for width == 1
C++64-Clang10:        : secs  4.9
C++64-Clang10-LTO     : secs  4.6
C++64-Clang10-LTO     : secs  4.1, removed trampoline
C++64-MSVC+TCC        : secs 11.6, 30% speedup vs interpreter!
C++64-MSVC+TCC        : secs 12.5, some temp setbacks due to lval refactor etc.
C++64-Clang10-LTO     : secs  3.4, moved vars to local array, fastest yet!
C++64-MSVC            : secs  5.4, moved vars to local array, somehow doesn't help.
C++64-MSVC+TCC        : secs 13.8, moved vars to local array, somehow worse!
C++64-MSVC            : secs  4.3, deeper inlining.
C++64-MSVC            : secs  4.2, explicit stackptr.
C++64-Clang10-LTO     : secs  3.3, explicit stackptr.
C++64-MSVC+TCC        : secs 13.1, explicit stackptr.
C++64-MSVC+TCC        : secs 12.5, newer VS updates?

debug speed:

    C++-msvc release: 5.5
    C++-msvc debug: 626 (114x), RTC off: 198.3 (36x)
    JIT-msvc release 12.7
    JIT-msvc debug: 369 (29x), RTC off: 194.5 (15x)
    C++-clang release: 3.7
    C++-clang debug: 53.6 (14x)
    JIT-clang release: 12.7
    JIT-clang debug: 61.4 (4.8x)

compiletime speed:

totslike.lobster + dependencies: 2500 loc / 100KB compiles in 0.0106 seconds (averaged from
1000 runs), which is about 9MB/sec, or 222 kloc/sec.

Parse: 30%
Typecheck: 41%
Optimizer: 10%
Codegen: 2%

uses about 6MB of process memory to run.

DEPENDENCIES
============


node.h
    [typechecker.h]
    [codegen.h]

lex.h
    ttypes.h

idents.h
    [node.h]
    natreg.h

disasm.h
    natreg.h
        vmdata.h
            il.h
    bytecode_generated.h
